\section{Model checking for synchronisation linearisation}
\label{sec:modelChecking}

In this section we describe how to analyse a synchronisation object using
model checking, to gain assurance that it satisfies synchronisation
linearisation.  We present our approach within the framework of the process
algebra CSP~\cite{awr:ucs} and its model checker FDR~\cite{fdr3,fdr-manual}.
We assume some familiarity with the syntax of CSP.

In particular, we use checks within the traces model of CSP\null.  This model
represents a process~$P$ by its traces, denoted $traces(P)$, i.e.~the finite
sequences of visible events that~$P$ can perform.  Given processes $P$
and~$Q$, FDR can test whether $traces(P) \subseteq traces(Q)$.  Here $P$ is
typically a model of some system that we want to analyse, and $Q$ is a
specification process that has precisely the traces that correspond to the
desired property.

\framebox{Limitations} of model checking.

We describe how to test for synchronisation linearisation within this
framework.  We start with the case of heterogeneous binary synchronisations;
we describe how to generalise at the end of this section.

We build a CSP model of the synchronisation object.  Such modelling of a
concurrent object is well understood, so we don't elaborate in detail.
Typically CSP processes representing threads perform events to read or write
shared variables, acquire or release locks, etc.  The shared variables, locks,
etc., are also represented by CSP processes.  An example for a synchronous
channel can be found in~\cite{gavin:syncChan}.

We assume that the model includes the following events:
%
\begin{itemize}
\item \CSPM{call}$.t.op.x$ to represent thread~$t$ calling operation~$op$ with
  parameter~$x$; 

\item \CSPM{return}$.t.op.y$ to represent thread~$t$ returning from
  operation~$op$ with result~$y$.
\end{itemize}
%
We assume that all other events, describing the internal operation of the
synchronisation object, are hidden, i.e.~converted into internal events.

We now describe how to test whether the model satisfies synchronisation
linearisation with respect to a specification object.  We construct a
specification process (\CSPM{Spec}, below) that allows precisely traces of
\CSPM{call} and \CSPM{return} events that are synchronisation linearisable.
We construct this specification process from several components.

We build a process \CSPM{SyncSpec} corresponding to the specification object.
We assume this process uses events of the form
\CSPM{sync}$.t_1.t_2.x_1.x_2.y_1.y_2$ to represent a synchronisation between
threads~$t_1$ and~$t_2$, calling $op_1(x_1)$ and~$op_2(x_2)$, and receiving
results~$y_1$ and~$y_2$, respectively.  For example, for the synchronous
channel, we would have
%
\begin{cspm}
SyncSpec = sync?t1?t2?x?u!u!x -> SyncSpec
\end{cspm}

If the synchronisation object or specification object has unbounded state, we
have no chance of modelling it using finite-state model checking.  However, we
can often build approximations.  For example, we could approximate (in an
informal sense) the synchronous channel with sequence counter by one where the
sequence counter is stored mod 5.  Then the specification object can
be modelled by
%
\begin{cspm}
SyncSpec = SyncSpec'(1)
SyncSpec'(ctr) = sync?t1?t2?x?u!ctr!(x,ctr) -> SyncSpec'((ctr+1)%5)
\end{cspm}

We then build a \emph{lineariser} process for each thread as follows.
%
\begin{cspm}
Lineariser(t) = 
  call.t.op£\s1£?x£\s1£ -> sync.t?t£\s2£!x£\s1£?x£\s2£?y£\s1£?y£\s2£ -> return.t.op£\s1£.y£\s1£ -> Lineariser(t)
  []
  call.t.op£\s2£?x£\s2£ -> sync?t£\s1£!t?x£\s1£!x£\s2£?y£\s1£?y£\s2£ -> return.t.op£\s2£.y£\s2£ -> Lineariser(t)
alpha(t) = {| call.t, return.t, sync.t.t£\s1£, sync.t£\s1£.t | t£\s1£ <- ThreadID, t£\s1£ != t |} 
\end{cspm}
%
This process ensures that between each \CSPM{call} and \CSPM{return} event
of~\CSPM{t}, there is a corresponding \CSPM{sync} event.  

We then combine together the specification process with the linearisers,
synchronising on shared events: this means that each
\CSPM{sync.t}\s1\CSPM{.t}\s2 event will be a three-way synchronisation between
\CSPM{SyncSpec}, \CSPM{Lineariser(t}\s1\CSPM{)} and
\CSPM{Lineariser(t}\s2\CSPM{)}.  
\begin{cspm}
Spec£\s0£ = SyncSpec [| {| sync |} |] (**|| t <- ThreadID @ [alpha(t)] Lineariser(t))
\end{cspm}
Every trace of \CSPM{Spec}\s0 represents an interleaving between a possible
history of the concurrent object (\CSPM{call} and \CSPM{return} events) and a
compatible legal history of the specification object (\CSPM{sync} events).

Finally, we hide the \CSPM{sync} events. 
\begin{cspm}
Spec = Spec£\s0£ \ {| sync |}
\end{cspm}
%
Each trace of the resulting process represents a history for which there is a
compatible legal history of the specification object; i.e.~it has precisely
the traces that correspond to histories that are synchronisation linearisable.
It is therefore enough to test whether the traces of the model of the
synchronisation object are a subset of the traces of \CSPM{Spec} this can be
discharged using FDR.

We now generalise this approach.  For a synchronisation involving $k$ threads,
the corresponding \CSPM{sync} event contains $k$ thread identities,
$k$~parameters, and $k$~return values; each such event will be a
synchronisation (in the CSP specification) between $k$ linearisers and the
specification process.

For homogeneous synchronisations the identities of the threads (and
corresponding parameters and return values) may appear in either order within
the |sync| events.  The following definition of the lineariser allows this
(for $k = 2$). 
%
\begin{cspm}
Lineariser(t) = 
  let others = ThreadID-{t} within
  call.t.op?x -> (
    sync.t?t':others!x?x'?y?y' -> return.t.op.y -> Lineariser(t)
    []
    sync?t':others!t?x'!x?y'!y -> return.t.op.y -> Lineariser(t)
  )
\end{cspm}

Finally, for synchronisation objects with multiple synchronisation modes, the
specification process should have a different branch (with different
\CSPM{sync} events) for each mode.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Progress conditions}

A simple adaptation of the above check allows us to capture an interesting
progress condition, which we now describe.  We make the assumption that the
scheduler in the implementation schedules each operation infinitely often.
This is different from the assumption corresponding to the standard property
of lock freedom~\cite{herlihy-shavit}, which allows threads to be suspended
forever; however, it is consistent with how real schedulers behave.
%
Under this assumption, we require that if a synchronisation is possible,
such a synchronisation can happen, and the relevant threads are able to
return: in other words, the \CSPM{return} events become available. 

Part of our progress check is that the model of the system is divergence-free,
which can be tested by FDR\@.  Recall, that a divergence (in CSP) is an
infinite sequence of consecutive internal events.  In the case of the model of
a synchronisation object, this would represent a livelock, i.e.~where one or
more threads perform infinitely many steps without reaching a point where
they can return.  The check forbids such livelocks.

The other part of our progress check concerns stable failures.  Recall that a
stable failure of a process is a pair $(tr,X)$ representing that the process
can perform trace~$tr$ to reach a stable state (i.e.~where no internal event
is possible), where no event from~$X$ can be performed.  We test whether the
stable failures of the model of the synchronisation object are a subset of the
stable failures of the above \CSPM{Spec} process.  We explain the property
this test captures via examples.

Consider a model of the synchronous channel, and the trace
$\trace{\CSPMM{call.t}_1.\CSPMM{send}.4, \linebreak[1] \,
  \CSPMM{call.t}_2.\CSPMM{receive.unit}}$.  After this trace, \CSPM{Spec}
(internally) performs \CSPM{sync.t}\s1\CSPM{.t}\s2\CSPM{.4.unit.unit.4}, and
reaches a state where both \CSPM{return.t}\s1.\CSPM{unit} and
\CSPM{return.t}\s2\CSPM{.4} are available.  The test of the previous
paragraph requires that both of these events are also available in the model
of the system, i.e.~both threads are able to return.

In some cases, it might be nondeterministic which synchronisation, out of two
or more possibilities, occurs.  For example, consider the synchronous channel,
again, and the trace $\trace{\CSPMM{call.t}_1.\CSPMM{send}.4,\,
  \CSPMM{call.t}_2.\CSPMM{send.5},\, \CSPMM{call.t}_3.\CSPMM{receive.unit}}$.
After this trace, \CSPM{Spec} may nondeterministically perform either
\CSPM{sync.t}\s1\CSPM{.t}\s3\CSPM{.}\linebreak[1]\CSPM{4.unit.unit.4} or
\CSPM{sync.t}\s2\CSPM{.t}\s3\CSPM{.5.unit.unit.5}.  Subsequently, either
\CSPM{return.t}\s1.\CSPM{unit} and \CSPM{return.t}\s3\CSPM{.4} or,
respectively, \CSPM{return.t}\s2.\CSPM{unit} and \CSPM{return.t}\s3\CSPM{.5}
are available.  The check ensures that in each case \CSPM{t}\s3 can return,
and that either \CSPM{t}\s1 or \CSPM{t}\s2 can return (with \CSPM{t}\s3
returning the corresponding value).



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Alternative approach}

The approach described above, using lineariser processes to ensure that the
|sync| events are between the relevant |call| and \CSPM{return} events, can be
expensive.  However, we can do better in some cases.

By way of an analogy, testing a concurrent datatype for (standard)
linearisation is often easier when one can identify explicit linearisation
points: the specification can be written in terms of those linearisation
points.  We use a similar technique with synchronisation linearisation. 

Suppose we are considering a binary synchronisation object involving
operations~|op|\s1 and~|op|\s2.  Our approach requires the analyst to identify
points~$p_1$ and~$p_1'$ within |op|\s1, and a point~$p_2$ within~|op|\s2,
which we call \emph{signal points}.  These signal points must satisfy the
following conditions (which the test below verifies):
%
\begin{enumerate}
\item\label{mc:condition1} When particular invocations of |op|\s1 and |op|\s2
  synchronise, point~$p_1$ is reached before point~$p_2$, and point~$p_2$ is
  reached before point~$p_1'$ (for the corresponding signal points);

\item\label{mc:condition2} The return values of the two invocations are
  available at points~$p_1'$ and~$p_2$, respectively;

\item\label{mc:condition3} No other invocation reaches a signal point between
  points~$p_1$ and~$p_1'$.
\end{enumerate}

Typically, $p_1$ will be at or before |op|\s1 signals to |op|\s2; $p_2$~will
be at or after |op|\s2 receives that signal, and at or before it signals back
to~|op|\s1; and $p_1'$ will be at or after |op|\s1 receives that signal back.
Figure~\ref{fig:signal-points} gives an example.

%%%%%

\begin{figure}[thp]
\begin{scala}
object SyncChan[T]{
  private var slot: A = _
  private val mutex = new Semaphore; mutex.up
  private val signal1, signal2 = new Semaphore // initially down

  def send(x: A) = {
    mutex.down; slot = x
    signal1.up        // signal point £$p_1$£
    signal2.down      // signal point £$p_1'$£
    mutex.up
  }

  def receive = {
    signal1.down
    val result = slot // signal point £$p_2$£
    signal2.up; result
  }
}
\end{scala}
\caption{An implementation of a synchronous channel, using semaphores.  Signal
  points are indicated by comments.  }
\label{fig:signal-points}
\end{figure}

%%%%%

Note that condition~\ref{mc:condition1} and the fact that the signal points
occur within the corresponding invocations  imply that $p_2$ occurs within
\emph{both} invocations.  Thus we can use $p_2$ as the synchronisation point.

We augment the CSP models of the threads with the following events:
%
\begin{itemize}
\item |signal|\s1|.t|\s1|.x|\s1 performed by thread~|t|\s1 at point~$p_1$,
  where |x|\s1 is its parameter;

\item |signal|\s2|.t|\s2|.x|\s2|.y|\s2 performed by thread~|t|\s2 at
  point~$p_2$, where |x|\s2 is its parameter and |y|\s2 is its return value;

\item  |signal|$_1'$|.t|\s1|.y|\s1 performed by thread~|t|\s1 at
  point~$p_1'$, where |y|\s1 is its return value.
\end{itemize}
%
Note that the events representing the calls and returns of operations are no
longer necessary. 

We can then test whether the model of the synchronisation object refines the
following specification (with a suitable initial state).
%
\begin{cspm}
SyncSpec(state) = 
  signal£\s1£?t£\s1£?x£\s1£ -> signal£\s2£?t£\s2£?x£\s2£!f£\s2£(state,x£\s1£,x£\s2£) ->
  signal£$_1'$£.t£\s1£!f£\s1£(state,x£\s1£,x£\s2£) -> SyncSpec(update(state,x£\s1£,x£\s2£))
\end{cspm}
%
where |f|\s1 and |f|\s2 give the expected return values for the two
invocations, and |update| describes how the state is updated. 
The specification ensures that the above condition~\ref{mc:condition1} is
satisfied.  Hence, as described above, this ensures that the synchronisations
can be linearised in the order of the corresponding |signal|\s2 events. 

The above condition~\ref{mc:condition2} is necessary to ensure the return
values can be included in the |signal| events.  If this is not true of
|op|\s2, we could arrange for the CSP model of this operation to perform a
later signal, on channel |signal|$_2'$ with that value, and to use the
following specification:
%
\begin{cspm}
SyncSpec(state) = 
  signal£\s1£?t£\s1£?x£\s1£ -> signal£\s2£?t£\s2£?x£\s2£ ->
  signal£$_1'$£.t£\s1£!f£\s1£(state,x£\s1£,x£\s2£) -> signal£$_2'$£.t£\s2£!f£\s2£(state,x£\s1£,x£\s2£) ->
  SyncSpec(update(state,x£\s1£,x£\s2£))
\end{cspm}

Condition~\ref{mc:condition3} is necessary to avoid false positives with the
above specification process.  The specification process handles the signals
for a single synchronisation at a time.

This approach can be extended to a synchronisation between $k > 2$ operations,
with signal points occurring in the order
\[
p_1, p_2, \ldots p_{k-1}, p_k, p'_{k-1}, p'_{k-2}, \ldots p_1',
\]
(where the subscripts correspond to the indices of the operations), or maybe
some other permutation of the $p'_i$ events. 


