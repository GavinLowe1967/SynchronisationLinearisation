MONDAY:

Check locality theorem and tidy up (Sec 2.5)

Check progress section (2.6)

Locality result for progress.

"Compatible"

General result for testing, end of Section 3.

===============

Main changes:

TO DO: set linearisability

Locality

Improved definition of progressibility.

===============

Relate to set linearisation.

Capture relationship between concrete and abstract ops as a relation that
relates a multiset of concrete operations to the corresponding abstract
operation.  For example, for the synchronous channel:

{ ( { send(x), receive(()) }, sync(x,()) ) | x \in T }

** What's the purpose of requiring state == Zero in \overline{op}_1 in Fig 3?
   It ensures each op_1 and op_2 are consecutive, so maybe makes the
   construction clearer.

** In Prop 9, double-check the use of "h_s'" at the end of each part
   (corrected from the submission). 

Show locality/compositionality.

Observation: the composition of k identical stateless synchronisation objects
has the same external behaviour as a single one. 

Clarify the term "linearisation point".  We use it abstractly, rather than
representing a concrete step in the code. 

Talk about our experience of students trying to test synchronisation objects. 

Add Atomic Broadcast

Note that (non-unary) synchronisations are necessarily not wait-free, lock-free
or obstruction-free.

============

> Reviewer's Responses to Questions
> 
> 1. Are the objectives and the rationale of the study clearly stated?
> 
> Reviewer #1: Yes, the introduction does a good job at motivating the work.
> 
> Reviewer #3: Yes.
> 
> 2. If applicable, is the application/theory/method/study reported in
> sufficient detail to allow for its replicability and/or reproducibility? 
> 
> Reviewer #1: Mark as appropriate with an X:
> 
> Yes [X] No [] N/A []
> 
> Provide further comments here: The authors provide detailed enough proofs of
> their propositions, and the code is available online. 
> 
> Reviewer #3: Mark as appropriate with an X:
> 
> Yes [X] No [] N/A []
> 
> Provide further comments here:
> 
> 3. If applicable, are statistical analyses, controls, sampling mechanism,
> and statistical reporting (e.g., P-values, CIs, effect sizes) appropriate
> and well described? 
> 
> Reviewer #1: Mark as appropriate with an X:
> 
> Yes [] No [X] N/A []
> 
> Provide further comments here: I have some suggestions in the next question.
> 
> Reviewer #3: Mark as appropriate with an X:
> 
> Yes [] No [] N/A [X]
> 
> Provide further comments here:
> 
> 4. Could the manuscript benefit from additional tables or figures, or from
> improving or removing (some of the) existing ones? 
> 
> Reviewer #1: Mark as appropriate with an X:
> 
> Yes [X] No [] N/A []
> 
> Provide further comments here:
> 
> A minor criticism is that the examples considered seem rather toy-ish and
> small. Because of this, I would have liked to see some description of how
> many lines of code each of the examples takes to implement. It would also
> have been appropriate to describe qualitatively what kinds of bugs were
> introduced into the implementations of the synchronization objects. 

*** Consider this.  I think it's common for synchronisation objects to be
    quite short in terms of lines of code, but still quite tricky to get
    right.  

*** Discuss bugs.  Typically unexpected orders of threads running.  

> Although sometimes the difference in time between the direct and two-step
> methods is rather large, it might make sense to put both techniques on the
> same scale to make them easier to compare. 

*** Consider this. (pp 39, 40; figs 10, 11).  I don't think it would work for
    the barrier, but it would for the others.

> Lacking a more comprehensive dataset of implementations to analyze, I also
> question how representative of the class of all synchronization objects the
> ones chosen here are. 

*** I'm not sure that is answerable. 

> Reviewer #3: Mark as appropriate with an X:
> 
> Yes [] No [X] N/A []
> 
> Provide further comments here:
> 
> 5. If applicable, are the interpretation of results and study conclusions
> supported by the data? 
> 
> Reviewer #1: Mark as appropriate with an X:
> 
> Yes [X] No [] N/A []
> 
> Provide further comments here:
> 
> Reviewer #3: Mark as appropriate with an X:
> 
> Yes [X] No [] N/A []
> 
> Provide further comments here:
> 
> 6. Have the authors clearly emphasized the strengths of their
> study/theory/methods/argument? 
> 
> Reviewer #1: Mark as appropriate with an X:
> 
> Yes [] No [X] N/A []
> 
> Provide further comments here: Lacking a detailed comparison with related
> works, I did not find their arguments for the novelty and strengths of their
> techniques were well-argued. Please see the extended answer below for a more
> detailed discussion on this point. 

***

> Reviewer #3: Mark as appropriate with an X:
> 
> Yes [X] No [] N/A []
> 
> Provide further comments here:
> 
> 7. Have the authors clearly stated the limitations of their
> study/theory/methods/argument? 
> 
> Reviewer #1: Mark as appropriate with an X:
> 
> Yes [X] No [] N/A []
> 
> Provide further comments here:
> 
> Reviewer #3: Mark as appropriate with an X:
> 
> Yes [X] No [] N/A []
> 
> Provide further comments here:
> 
> 8. Does the manuscript structure, flow or writing need improving (e.g., the
> addition of subheadings, shortening of text, reorganization of sections, or
> moving details from one section to another)? 
> 
> Reviewer #1: Mark as appropriate with an X:
> 
> Yes [] No [X] N/A []
> 
> Provide further comments here:
> 
> Reviewer #3: Mark as appropriate with an X:
> 
> Yes [] No [X] N/A []
> 
> Provide further comments here:
> 
> 9. Could the manuscript benefit from language editing?
> 
> Reviewer #1: No
> 
> Reviewer #3: No

> ==================================================

> Reviewers' comments to authors
> 
> 
> Reviewer #1: The paper introduces a correctness criterion for objects with
> synchronization based on linearizability. Then, it compares this criterion
> with the standard linearizability. Then it moves to discussing and
> evaluating two testing techniques for their proposed criterion. 
> 
> The paper purports to introduce a novel generalization of linearizability to
> handle objects with synchronization. The paper, however, does not cite any
> of the literature on linearizability following the original paper by Herlihy
> and Wing. Particularly relevant is that several increasingly more general
> criteria for specifying concurrent objects have been proposed, which are
> much more natural than the one advocated here and can handle strictly more
> objects. I believe all the objects considered in this paper (even
> considering the proposed variations from Sec. 2.4) are already covered by
> set linearizability (later re-branded as concurrency-aware linearizability),
> not to mention by more recent generalizations that subsume set
> linearizability such as interval linearizability and compositional
> linearizability. 

*** Compare with set linearizability.  It does look similar.

[Random thoughts below.]

A Linearizability-based Hierarchy for Concurrent Specifications.  Armando
Castañeda, Sergio Rajsbaum, and Michel Raynal.  Communications of the ACM.
Vol. 66 No. 1, Pages: 86-97, 2023.

Reference: 
https://cacm.acm.org/research/a-linearizability-based-hierarchy-for-concurrent-specifications/.
Also look at refs 20 and 30 from there (set linearizability); 8 (interval
linearizability); 33 (intermediate value; not relevant, but shows willing).

20: 
30: https://dl.acm.org/doi/pdf/10.1145/197917.198176

Hemed, N., Rinetzky, N., and Vafeiadis, V. Modular verification of concurrency-aware linearizability. In Proceedings of 29th Symp. Distributed Computing. Springer LNCS 9363 (2015), 371–387.
978-3-662-48653-5.pdf

I think they don't consider the question of how to specify a synchronisation
object.  They just assume the allowed histories are given.  These seems to be
one of our contributions.  

Maybe show that the algorithm in Figure 3 does not satisfy our property, and
that our testing mechanism can detect this. 

I think the set-linearizable version of the lattice problem can be specified
in our setting by

class Spec{
  private var state: Set[L] = {}
  def sync_j(x_1: L, ... x_j: L): (L,...,L) = {
    state = state \union {x_1,...,x_j); val ub = \sqcup state; (ub,...,ub)
  }
}

where sync_j synchronises j threads, and there is a sync_j for each j = 1,.... 

Interval linearizability: 
Castañeda, A., Rajsbaum, S., and Raynal, M. Unifying concurrent objects and
distributed tasks: interval-linearizability. J. ACM 65, 6 (2018), Article 45. 
Castaneda, A., Rajsbaum, S., Raynal, M.: Specifying concurrent problems: beyond
linearizability and up to tasks. In: DISC (2015)

Also look at
Scherer III, W.N., Scott, M.L.: Nonblocking concurrent data structures with con-
dition synchronization. In: Guerraoui, R. (ed.) DISC 2004. LNCS, vol. 3274,
pp. 174–187. Springer, Heidelberg (2004)
978-3-540-30186-8_13.pdf
Sounds a bit like two-step linearizability.

"Scherer and Scott~\cite{...} consider a setting where an operation may be
linearised in several steps, similar to our two-step linearisation.  Their
interest is in partial concurrent datatypes, where an operation may have a
nontrivial precondition.  Such an operation is linearised by (1)~an initial
request (where the operation registers itself); (2)~some number of
unsuccessful follow-ups (where the precondition is found not to be satisfied);
(3)~a successful follow-up (where the precondition holds, and the operation
takes effect)."

> The formal treatment of synchronization objects is not satisfactory. While
> Sec. 2.1-2.3 are satisfactory in their formalism, they only handle a small
> subset of all 'synchronization objects'. Sec. 2.4, which is supposed to
> extend it to the class of all synchronization objects discussed earlier in
> Sec. 1, is mostly informal. So the paper has only convincingly covered the
> subclass of synchronization objects described in the introduction to Sec
> 2. 

We have made this more formal in Section 2.4, by defining which operations of
the synchronisation object can synchronise together, and the corresponding
operation on the synchronisation specification object. 

> Their paper also has a notable omission from the point-of-view of the
> theory of linearizability in not mentioning whether the criterion satisfies
> locality. 

We have now included a proof of locality for synchronisation linearisation
(Section 2.5), and for synchronisation progressibility (Section 2.6). 

> Now, I believe that a formal treatment of the fully general criterion
> informally suggested in Sec. 2.4 will be weaker or, most likely, equivalent
> to set linearizability. If that is the case, the paper merely provides a
> more convoluted, although perhaps specialized and more convenient for their
> practical applications later in the paper, re-formulation of set
> linearizability. This renders most of Sec. 2 and Sec. 3 as
> non-contributions, if not misleading because of the lack of acknowledgement
> of the pre-existing advances on linearizability and of a dedicated related
> works section. 

** Add comparison. 

> A different concern is that the specifications here are rather unusual in
> that an object with reasonable operations, say send and receive, becomes an
> object with a single operation called sync. On its face, this does not have
> the same interface as the original object. Note that this is not a
> conservative generalization of standard linearizability, which keeps the
> same interface in the specification. 

We have now described how to capture the relationship between operations of
the synchronisation object and of the synchronisation specification object,
via a "synchronisation relation" (Section 2.4).  

> Meanwhile, the criteria I mention
> above, including set linearizability, all use the same interface for the
> concrete object and the specification. 

The earlier work considered the set of legal histories as "given" (which was
appropriate in their context).  Here, part of our focus is in specifying what
the legal histories are.  We think that encapsulating the specification in a
synchronisation specification object, with an operation for each type of
synchronisation, is the easiest way to do that.

> The liveness property the paper proposes also seems inappropriate for
> multiple reasons. I believe there are two main critical issues. The first is
> that when you have threads under non-deterministic interleaving operations
> may be only may-convergent. This means that you may be able to find an
> extension of a trace s where all the calls that were pending in s have a
> return, even though they might have diverged.

We don't fully understand that comment.  However, we think that the reviewer
has misunderstood our intention, which was that progressibility is not
satisfied by a system that might diverge.  But that misunderstanding reflects
that the definition was not as clear as it might have been.  We have
reformulated it, in terms of state machines.  In particular, it should now be
clear that if the system can diverge, it is not progressible. 

>  Second, it is a well-known
> result that linearizability does not reflect liveness (i.e. it may be that s
> linearizes to t, t satisfies a liveness property, but s does not). The
> progress property here is based on essentially checking that the
> linearizations satisfy some progress property, so it is inherently
> flawed. 

We don't fully understand this.  What are s and t here?  We presume a
concurrent object and its sequential specification.  Assuming so, this doesn't
correspond to progressibility.  The property we define is that if the
linearisation includes a synchronisation, then the relevant concrete
operations must eventually return: in your terms, if t can make progress, then
s must also make progress.

> Its testing was only presented rather informally and did not seem
> like a robust testing technique, as it seems to boil down to "if it times
> out it probably dead-locked". 

That's the basic approach -- but it seems to work!  We have discussed the
choice of the timeout time further in Section 8.

> What might be novel is the second half of the paper about linearizability
> testing for synchronization objects. While I am not an expert in the
> literature on testing, I am not convinced these contributions are
> substantial enough to justify publication, especially given the other faults
> with the paper. This is aggravated by the lack of a dedicated related works
> section and a detailed account of how the paper compares to the pre-existing
> works. 

** Can we improve related work?  I'm not aware of related work.  Both do search.

> Moreover, the result in Sec. 6.2, that synchronization
> linearizability is NP-complete, seems like a trivial result given that
> synchronization linearizability subsumes standard linearizability, and
> checking for linearizability is already known to be NP-complete. 

We agree that the result in Section 6.2 is unsurprising (but, nevertheless, we
think it's worth stating).  We consider the result in Section 6.5 to be more
surprising.

> At this
> point, I was also expecting some comparison with static analysis and model
> checking techniques. The paper, however, only cites quite an old reference
> (other than a reference to a work by the same author). Even just last year,
> there has been a wealth of model checking techniques proposed for
> linearizability. 

** Is this relevant?  The point is that these are techniques that can be used
   by typical software engineers (or students). 

> Minor Comments:
> 
> Pg. 7 L. 21-33: The text here only explains what 'require' is, it does not
> explain 'guard'. Even if it is just supposed to be some boolean function, it
> would be best to briefly explain it. 

We've now said this.
 
> Pg. 8 L. 28-31: 'Datatype' is probably not the correct terminology
> here. 'Object' is probably the best terminology (and is used in the original
> linearizability paper and subsequent literature on linearizability, but even
> 'concurrent data structure' or 'concurrent algorithm' would be better
> terminology). The use of datatype seems to be repeated throughout the
> paper. It is surprising that the paper uses datatypes for 'concurrent
> objects' datatypes, but use 'synchronisation object'. Note that
> 'synchronisation objects' are just special cases of the objects already
> called 'concurrent objects' in the literature. So it is unclear to me why
> the discrepancy in the terminology was introduced in this paper. 

We're using the term "concurrent datatype" to mean an implementation of an
abstract datatype that supports concurrency -- and we've now said that.  These
are the objects for which linearisation is the normal correctness criterion.
In particular, synchronisation objects are *not* concurrent datatypes.  The
term "concurrent object" would seem to a wider category, that includes both of
these classes, so we don't want to use that term when we mean (what we're
calling) "concurrent datatype".  We need some term for this subclass of
concurrent objects, and "concurrent datatype" is the best we've come up with. 

> Pg. 10 L. 25-32: I would suggest to the authors to revise their definitions
> so that the property 'linearizable' is not a unary property and instead is
> phrased as 'linearizable w.r.t. to Spec', as you can only make sense of a
> concurrent object 'o' being 'linearisable' if you also have its
> 'Spec'. While stating linearisability as a unary property is common (as was
> done in the original paper), I would say this is a fault in the
> presentation. If 'Spec' is not taken into account in the definition
> (i.e. linearisability is a unary property), then every concurrent object is
> linearizable (per the classic result that every partial order admits a
> refinement to a linear order) making linearizability the trivial property
> 'True'. This is especially an issue here, as the paper admits that Spec may
> be non-deterministic. 

We've done this, and likewise in the definition of synchronisation
linearisation. 


=======================================================
 
> Reviewer #3: Summary:
> 
> The paper presents a way of specifying and testing the correctness of
> a synchronization object in concurrent programming.
> 
> Section 1 explains that a synchronization object defines a point at which
> each thread waits until the other threads have reached that same point.
> Once all the threads have reached that point, they can all continue.
> This notion of synchronization object includes synchronous channels,
> value exchangers, and barriers.
> It also includes timed variants, stateful variants, and
> termination-enforcing variants.
> 
> Section 2 introduces synchronisation linearisation and
> synchronisation progressibility as the key correctness properties of
> a synchronization object.
> Part of the idea of synchronisation linearisation is well known from
> linearisation.
> Specifically, the behaviour is consistent with that the synchronisation
> happens atomically at some point, called the synchronization point.
> The extension is that in synchronisation linearisation,
> the synchronization point is the _same_ across multiple threads.
> 
> Section 3 explains the relationship between linearization and
> synchronisation linearisation. The idea is that
> a synchronisation linearisation is a two-step linearization.
> 
> Sections 4-5 show how to adapt a method for testing for linearisation to
> testing for synchronisation linearisation.
> 
> Section 6 shows how to test for synchronisation linearisation in a manner that
> is more direct that in Section 4-5.
> It considers the worst-case complexity of the problem.
> 
> Sections 7-8 describe an implementation of the testing techniques followed by
> a report on experiments.
> 
> 
> Evaluation:
> 
> The paper is easy to read and has many helpful examples and illustrations.
> Overall, the paper has a main insight about synchronization and it follows up
> with additional insights about complexity, testing, etc.
> This paper is exactly the kind of paper that I expect and hope to see
> in Science of Computer Programming.
> I do have suggestions for improvement that I hope are doable, see below.
> 
> Section 1 does a good job of introducing the rich world of
> synchronization objects.
> 
> In Section 2, the path from linearization to synchronization linearization
> is clear.
> 
> In Section 3, the paper shows how to map
> any synchronisation linearisation to a two-step linearization.
> The description of this map (Figure 3) is 20 lines and a little complicated.
> I got convinced that I would much rather work with
> synchronisation linearisations that think about two-step linearizations.

That's a fair comment!  We've briefly acknowledged this at the start of
Section 3.2.  This section is more a proof of possibility than a suggestion
that this is the easiest way.  (Somewhat related to this point: we note in
Section 6 that the direct algorithms tend to be easier to implement than the
two-step approach.)

> The proofs in Section 3 are given without specifying
> a semantics mathematically that could formalize Figure 3.
> The paper is careful about stating the main result Proposition 8 as
> a proposition, rather than a theorem, presumably because of "no semantics".
> I have landed on the view that the lack of formal semantics is okay because
> Section 3 communicates a nontrivial insight clearly.
> Others can formalize it.

The semantics of Figure 3 is the set of legal histories that the object
allows.  We've now noted that.  Lemma 7 identifies the important properties of
those histories.

> I like how the paper draws a straight line from the conceptual constructions in
> Section 3 to the testing framework in Section 5.
> 
> In Section 6, the proof of NP-completeness for a fairly general case is
> by reduction to a result for linearisation from 1997 by Gibbons and Korach.
> This is done with a fairly minimal amount of detail that requires the reader to
> think through some points, which is more work than "it is clear".
> However, given that the main point is that the NP-completeness is what we
> would expect (if we know the 1997 paper), I think all this is okay.

We've made clearer (in the Introduction, and at the start of Section 6) that
it's an unsurprising result.  We consider the result in Section 6.5 to be more
surprising. 

> Major suggestions:
> 
> - Section 2: does the definition of synchronisation progressibility stem from
> a known idea? The paper compares synchronisation progressibility to
> lock freedom and concludes that they are quite different.
> I would like to see more text about the origin story of
> synchronisation progressibility.

*** Relate to CSP FD checks (at least, under assumption 1 on page 14). -- related
work section

But it seems to be the natural condition to me.    

> - P.16: "We show that there is no corresponding
> linearisation specification Spec, i.e. such that
> for every concurrent history h, h is synchronisation linearisable
> with respect to SyncChanSpec if and only if
> h is linearisable with respect to Spec":
> add an explanation of why we here need both SyncChanSpec and Spec.
> Perhaps SyncChanSpec and Spec could be the same thing?

We're asking whether the property of being synchronisation linearisable with
respect to SyncChanSpec can be captured as an instance of linearisable.
That's equivalent to asking whether there is a linearisation specification
Spec such that an implementation is synchronisation-linearisable with
respect to SyncChanSpec if and only if it is linearisable with respect to
Spec.  And that's equivalent to the sentence you've quoted.  

We've added a few words, and stated the result as a proposition.  We hope that
makes it clearer.

> I would like to see more text about why proving the stated property is
> what we need to show why linearisation and synchronisation linearisation
> are not equivalent in general.
> I think that a key part of the value of the paper stems from
> that the stated property is property is true.
> To me, this means that the paper should have more text about it.
> One additional idea could be to make it into a theorem.

> - P.23, Section 3 ends with
> "We believe that these techniques can be adapted to
> all the other synchronisation objects we have considered":
> I suggest that the paper already in Section 1 divides the many examples
> into two buckets: the ones Section 3 can handle and the others.
> This way, the reader can have a strong sense already from Section 1 about
> how far the paper goes and where future work can begin.

We have now stated that more positively, that the techniques *can* be adapted
to the other synchronisation objects.  We have sketched the general
construction, but think it's best not to give the details explicitly, as
they're fiddly and uninteresting. 

> - In Section 6, I would like to see text about whether we should be surprised
> that the stateless case can be solved in O(n^2) time.
> Does something similar happen with linearization?
> If not, then I think it is a big deal that can help motivate why
> the concept of a synchronisation linearisation is an interesting one.

In practice, linearisation is only used with stateful objects.  Linearisation
in the stateless case would amount to checking each invocation is correct in
isolation, so is O(n).  We've noted this in the introduction to Section 6.

??? Is this the best place? 

We can't decide if the O(n^2) result is surprising, so we haven't said
anything: different people find different things surprising.  It's not
out-of-line with the O(n) result for stateless linearisation.

> - Section 6 divides the overall problem into categories and gives
> a complexity result for each one. I would like to see Section 6 end with
> a table that has two columns, one for linearization and one for
> synchronisation linearisation.
> In the table, each row can be a category, like "stateful",
> "stateless", "binary heterogeneous stateless", and
> "binary homogeneous stateless".
> I picture each entry in the table as the worst-case time complexity.
> Such a table will hammer home some similarities and differences between
> algorithms for linearization and for synchronisation linearisation.

Given that linearisation is only applied to stateful objects, in practice, we
don't think such a comparison table really makes sense.  At most, it would
have two rows, "stateless" and "stateful", because the different subcategories
of statelessness don't have analogues for linearisation.  However, we have
added a summary table for synchronisation linearisation at the end of the
introduction to Section 6. 

> - P.37: the paper lists three questions, good ones, indeed.
> I would prefer that the author follows a particular point in
> the SIGPLAN Empirical Evaluation Guidelines, namely the first one:
> avoid "Claims not explicit".
> This can be done by stating the _answers_ to the questions right away.
> Like:
> \item Question1? Answer1.
> \item Question2? Answer2.
> \item Question3? Answer3.
> This enables the reader to know where the next five pages are going and
> how the author would summarize them.
> Indeed, I think those five pages in their current form has no such summary
> and I think the best place to put the summary is with the questions.

We have done this.  Thanks for the suggestion.

> Minor suggestions:
> 
> - P.8, "Our definition has much in common with the well
> known notion of linearisation":
> This makes me uncomfortable. Please be explicit about
> any changes you make to the standard definition of linearisation.

We've added a few words there, and a slightly fuller description at the start
of Section 2.3.

> - P.8: "is a execution identity" -> "is an execution identity".

Done.

> - Section 3, p.16, l.4: what is "linearisation specification"?
> This is the first time the paper uses this term.

That was a typo: we meant "linearisation specification *object*", now
corrected. 

> - P.20: "The two-step linearisation specification object can often be
> significantly simplified from the template definition above":
> Please add more text about this and the example of p.20.
> What is the nature of the simplification? Why is it a simplification?

Formally, it's a data refinement.

> Why does it matter? (Let me add that if it doesn't matter, then remove it,
> where "it" is p.20, l.40-56.)

We think you're right that it doesn't really matter: the result here is a
theoretical one, rather than aiming to be particularly efficient or clear.
We've removed that paragraph.

> - P.24: the title of Section 5 is "Hacking the linearisability framework".
> The author is clear on that he consider what follows to be a hack, but
> the text also uses the word "adaptation".
> I suggest that the title of Section 5 could be
> "Adapting the linearisability framework", or something similar.
> I emphasize that this is a minor suggestion.
> The author can disagree and keep the title of Section 5.

We've done this.

============================

Actions:

Search for related work

Read set linearizability

Read  Nonblocking concurrent data structures with condition synchronization
