\begin{frontmatter}
\title{Synchronisation: Specification and Testing}

\author{Jonathan Lawrence}
\ead{jonathan@tbtl.com}
\affiliation{organization = {The Blockhouse Technology Ltd.}, city = {Oxford},
  country = {UK}}

\author{Gavin Lowe\corref{cor1}}
\ead{gavin.lowe@cs.ox.ac.uk} 
\affiliation{organization = {St Catherine's College, University of
    Oxford}, country = {UK}}
\cortext[cor1]{Corresponding author.}

\journal{Science of Computer Programming}

\begin{abstract}
We study \emph{synchronisation objects}: objects that allow two or more
threads to synchronise, each waiting until the other threads have reached a
particular point, and maybe exchanging data.  We define a correctness
condition for such synchronisation objects, which we call
\emph{synchronisation linearisation}: informally, the synchronisations appear
to take place in a one-at-a-time order, consistent with the calls and returns
of operations on the object, and giving correct results.  We also define a
liveness condition, which we call \emph{synchronisation progressibility}:
informally, executions of operations don't get stuck when a synchronisation is
possible.  We show that synchronisation linearisation can be reduced to a
variant of standard linearisation, which we call \emph{two-step
  linearisation}, where each operation of the synchronisation object is
linearised in \emph{two} steps.

We consider testing of implementations of synchronisation objects.  The basic
idea is to run several threads that use the object, record the history of
operation calls and returns, and then test whether the resulting history
satisfies synchronisation linearisation and progressibility.  We present
algorithms for this last step, and give results concerning the complexity of
the problem.  We describe an implementation of such a testing framework, and
present experimental results.
\end{abstract}

\begin{keyword}
Concurrent programming \sep
synchronisation \sep specification \sep linearisation \sep synchronisation
linearisation \sep synchronisation progressibility \sep two-step linearisation
\sep testing.
\end{keyword}
\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

In many concurrent programs, it is necessary at some point for two or more
threads to \emph{synchronise}: each of the threads waits until the other
threads have reached a particular point before continuing; in addition, the
threads can exchange or combine data.  Reasoning about programs can be easier
when synchronisations are used: it helps to keep threads in consistent stages
of the program, and so makes it easier to reason about the states of different
threads. (The word ``synchronisation'' is used in a couple of different ways
within concurrent programming: we use it in the sense just described, where
every thread waits for the others, rather than for more general coordination
between threads, such as via a semaphore which allows asynchrony between a
signal and the receipt of the signal.)

We study synchronisations in this paper: we describe how synchronisations can
be specified, and what it means for such a specification to be satisfied.  We
also describe techniques for testing implementations. 

We start by giving some examples of synchronisations in order to illustrate
the idea.  (We use Scala notation; we explain non-standard aspects of the
language in footnotes.)  In each case, the synchronisation is mediated by a
\emph{synchronisation object}.

Perhaps the most common form of synchronisation object is a synchronous
channel, e.g.~\cite{H78,occam,andrews,JCSP,sufrin:CSO,DK-go}.  Such a channel
might have signature\footnote{The class is polymorphic in the
  type~{\scalashape A} of data.  The type {\scalashape Unit} is the type that
  contains a single value, the \emph{unit value}, denoted~{\scalashape ()}.}
%
\begin{scala}
class SyncChan[A]{
  def send(x: A): Unit
  def receive(): A
}
\end{scala}
%
Each execution of one of the operations must synchronise with an execution
of the other operation: the two executions must overlap in time.  If an
execution |send(x)| synchronises with an execution of |receive|, then the
|receive| returns~|x|.

Each synchronisation of a synchronous channel involves executions of two
\emph{different} operations (|send| and |receive|); we say that the
synchronisation is \emph{heterogeneous}.  By contrast, sometimes two
executions of the \emph{same} operation may synchronise; we say that the
synchronisation is \emph{homogeneous}.  For example, an
\emph{exchanger}~\cite{HSY2004,herlihy-shavit} has the following signature:
%
\begin{scala}
class Exchanger[A]{
  def exchange(x: A): A
}
\end{scala}
%
When two threads call |exchange|, the executions can synchronise, and each
receives the value passed in by the other.

For some synchronisation objects, synchronisations might involve more than two
threads.  For example, a \emph{barrier synchronisation}
object~\cite{andrews,JCSP,SCL} can be used to synchronise~|n| threads:
%
\begin{scala}
class Barrier(n: Int){
  def sync(me: Int): Unit
}
\end{scala}
%
Each thread is assumed to have an integer thread identifier in the range
$\range{0}{\sm{n}}$.  Each thread~|me| calls |sync(me)|, and no execution
returns until all~|n| have called it.  We say that the synchronisation has
\emph{arity}~|n|.

A \emph{combining barrier}~\cite{andrews,SCL}, in addition to acting as a barrier
synchronisation, also allows each thread to submit a parameter, and for all to
receive back some function of those parameters.\footnote{The Scala type
  {\scalashape (A,A) =}$>$ {\scalashape A} represents functions from pairs of
  {\scalashape A} to~{\scalashape A}.}
%
\pagebreak[3]
%\begin{samepage}
\begin{scala}
class CombiningBarrier[A](n: Int, f: (A,A) => A){
  def sync(me: Int, x: A): A
}
\end{scala}
%\end{samepage}
%
The function |f| is assumed to be associative.  If |n| threads call |sync|
with parameters $x_1, \ldots, x_{\ss n}$, in some order, then each receives
back $\sm f(x_1, \sm f(x_2, \ldots \sm f(x_{{\ss n}-1}, x_{\ss n}) \ldots ))$.
(In the common case that |f| is commutative, this result is independent of the
order of the parameters.)

Some synchronisation objects have multiple modes of synchronisation.  For
example, consider a synchronous channel with timeouts: each execution might
synchronise with another execution, or might timeout without
synchronisation~\cite{sufrin:CSO,SCL}.  Such a channel has a signature as
follows.
%
\begin{scala}
class TimeoutChannel[A]{
  def send(x: A): Boolean
  def receive(): Option[A]
}
\end{scala}
%
The |send| operation returns a boolean to indicate whether the send was
successful, i.e.~whether it synchronised.  The |receive| operation can return
a value |Some(x)| to indicate that it synchronised and received~|x|, or can
return the value |None| to indicate that it failed to synchronise\footnote{The
  type {\scalashape Option[A]} contains the union of such values.}.  Thus an
execution of each operation may or may not synchronise with an execution of
the other operation.  Unsuccessful executions of |send| and |receive|
can be considered \emph{unary} synchronisations.  

Similarly, a timeout exchanger~\cite{HSY2004,herlihy-shavit} can allow threads
to exchange; but if a thread fails to exchange, it can return without
synchronising.  It has a signature as follows.
\begin{scala}
class TimeoutExchanger[A]{
  def exchange(x: A): Option[A]
}
\end{scala}


So far, our example synchronisation objects have been \emph{stateless}: they
maintain no state from one synchronisation to another.  By contrast, some
synchronisation objects are \emph{stateful}: they maintain some state between
synchronisations, which might affect synchronisations.  As a toy example,
consider a synchronous channel that maintains a sequence counter, and such
that both executions receive the current value of this counter.
\begin{mysamepage}
\begin{scala}
class SyncChanCounter[A]{
  private var counter: Int
  def send(x: A): Int      // Result is sequence counter.
  def receive(): (A, Int)  // Result is (value received, sequence counter).
}
\end{scala}
\end{mysamepage}

% Variations: homogenous case; different modes

Some implementations of synchronous channels allow the channel to be
closed~\cite{JCSP,sufrin:CSO}, say by a unary operation |close|.
\begin{scala}
class CloseableChan[A]{
  def send(x: A): Unit
  def receive(): A
  def close(): Unit
}
\end{scala} 
%
Calls to |send| or |receive| after the channel is closed throw an exception.
Thus such an object is stateful, with two states, open and closed; and the
operations have different modes of synchronisation, either successful or
throwing an exception.

An \emph{enrollable barrier}~\cite{alting-barrier} is a barrier
that allows threads to enrol and resign (via unary operations):
%
\begin{scala}
class EnrollableBarrier(n: Int){
  def sync(me: Int): Unit
  def enrol(me: Int): Unit
  def resign(me: Int): Unit
}
\end{scala} 
%
Each barrier synchronisation is between all threads that are currently
enrolled, so |sync| has a variable arity.  The barrier has a state, namely the
currently enrolled threads.

A \emph{terminating queue} can also be thought of as a stateful
synchronisation object with multiple modes.  Such an object mostly acts like a
standard partial concurrent queue: if a thread attempts to dequeue, but the
queue is empty, it blocks until the queue becomes non-empty.  However, if a
state is reached where all the threads are blocked in this way, then they all
return a special value to indicate this fact.  In some concurrent algorithms,
such as a concurrent graph search, this latter outcome indicates that the
algorithm should terminate.  Such a terminating queue might have the following
signature, where a dequeue returns the value |None| to indicate the
termination case.
%
\begin{scala}
class TerminatingQueue[A](n: Int){ // £n£ is the number of threads   
  def enqueue(x: A): Unit
  def dequeue: Option[A]
}
\end{scala} 
%
The termination outcome can be seen as a synchronisation between all |n|
threads.  This terminating queue combines the functionality of a
concurrent datatype and a synchronisation object.


%% In general, a synchronisation will involve some number~$k$ of threads, calling
%% operations of the form
%% %
%% \begin{scala}
%%   def op£\s1£(x£\s1£: A£\s1£): B£\s1£
%%   ...
%%   def op£\s k£(x£\s k£: A£\s k£): B£\s k£
%% \end{scala}
%% %
%% Each thread passes in some data, and receives back a result. 

In this paper, we consider what it means for such a synchronisation
object to be correct.  We also present techniques for testing correctness of
implementations.

In Section~\ref{sec:spec} we describe how to specify a synchronisation object:
we call the property \emph{synchronisation linearisation}.  The definition has
similarities with that of
\emph{linearisation}~\cite{herlihy-wing,herlihy-shavit}.  Linearisation is the
standard correctness property for concurrent datatypes (by which we mean
implementations of abstract dataypes, such as sets, mappings, stacks and
queues, that support concurrent operations).  However, synchronisation
linearisation talks about synchronisations between executions of operations,
whereas linearisation talks about single executions.  Informally, the
synchronisations should appear to take place in a one-at-a-time order,
consistent with the calls and returns of operations on the synchronisation
object.
%%  and with results as defined by a \emph{synchronisation specification
%%   object}.
We present a way to specify what sequences of synchronisations and what
return values are consider correct, via a \emph{synchronisation specification
  object}.

In fact, our property of synchronisation linearisation turns out to be the
same as \emph{set linearisation}~\cite{Neiger-1994}, also known as
\emph{concurrency-aware linearisation}~\cite{HRV-2015}.  We compare these
approaches with our own in Section~\ref{sec:related}.  We prefer the name
``synchronisation linearisation'' here, because it best describes our
intention.

We also define a liveness condition, which we call \emph{synchronisation
  progressibility}: informally, executions don't get stuck when a
synchronisation is possible.

In Section~\ref{sec:relating} we consider the relationship between
synchronisation linearisation and (standard) linearisation.  We show that
linearisation is an instance of synchronisation linearisation, but that
synchronisation linearisation is more general.  We also show that
synchronisation linearisation corresponds to a small adaptation of
linearisation, where an operation of the synchronisation object may correspond
to \emph{two} operations of the object used to specify linearisation; we call
this \emph{two-step linearisation}.

We then consider testing of synchronisation object implementations.  Our
experience from teaching students is that they often do not have a clear idea
about how to test a synchronisation object (we suspect the same is true of
other programmers).  Yet, implementing synchronisation objects is
tricky---subtle bugs are fairly common---and so good tests are important.

Our testing techniques are based on the techniques for testing (standard)
linearisation~\cite{wing-gong,gavin:lin-testing}, which we review in
Section~\ref{sec:lin-testing}: the basic idea is to record a history of
threads using the object, and then to check whether that history is
linearisable.
%
In Section~\ref{sec:testing-hacking} we show how this technique can be adapted
to test for synchronisation linearisation, using the result of
Section~\ref{sec:relating}, where an operation of the synchronisation object
may correspond to two operations of the specification object.

In Section~\ref{sec:direct} we show how synchronisation linearisation can be
tested more directly: we describe algorithms that check whether a history of a
synchronisation object is synchronisation linearisable.  We also present
various complexity results.  Deciding whether a given history is
synchronisation linearisable is NP-complete in general, in the stateful case.
However, it can be decided in polynomial time in the case of binary
(heterogeneous or homogeneous) stateless synchronisation objects.  But moving 
to synchronisations with arity greater than~2 is again NP-complete, even in
the stateless case. 


%% In Section~\ref{sec:modelChecking} we consider how the property of
%% synchronisation linearisation can be analysed via model checking.
%% \framebox{Cut this?} 

We describe the implementation of a testing framework in
Section~\ref{sec:implementation}; the framework supports both two-step
linearisation and the direct algorithms.  In Section~\ref{sec:experiments} we
describe experiments to determine the effectiveness of the testing techniques:
both find errors in faulty implementations of synchronisation objects very
quickly.  We sum up and discuss related work in Section~\ref{sec:conc}.

We consider our main contributions to be as follows.
%
\begin{itemize}
\item An exploration of the range of different synchronisation objects;

\item A general technique for specifying synchronisation objects, capturing
  both safety and liveness properties;

\item A study of the relationship between synchronisation linearisation and
  standard linearisation;

\item Algorithms for deciding whether a history of a synchronisation object is
  synchronisation linearisable, together with related complexity results;

\item A testing framework for synchronisation objects, and an experimental
  assessment of its effectiveness.
\end{itemize}
