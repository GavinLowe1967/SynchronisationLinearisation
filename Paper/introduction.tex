\begin{abstract}
We study \emph{synchronisation objects}: objects that allow two or more
threads to synchronise.  We define a correctness condition for such
synchronisation objects, which we call \emph{synchronisation linearisation}:
informally, the synchronisations appear to take place in a one-at-a-time
order, consistent with the invocations of operations on the object.  We also
define a progress condition, which we call \emph{synchronisation
  progressibility}: informally, invocations don't get stuck unnecessarily. 

We consider testing of implementations of synchronisation objects.  The basic
idea is to run several threads that use the object, record the history of
operation calls and returns, and then to test whether the resulting history
satisfies synchronisation linearisation and progressibility.  We present
algorithms for this last step, and also present results concerning the
complexity of the problem.
\end{abstract}

\section{Introduction}

In many concurrent programs, it is necessary at some point for two or more
threads to \emph{synchronise}: each thread waits until other relevant threads
have reached the synchronisation point before continuing; in addition, the
threads can exchange data.  Reasoning about programs can be easier when
synchronisations are used: it helps to keep threads in consistent stages of
the program, and so makes it easier to reason about the states of different
threads.

We study synchronisations in this paper: we describe how synchronisations can
be specified, and what it means for such a specification to be satisfied.  We
also describe techniques for testing implementations.

We start by giving some examples of synchronisations in order to illustrate
the idea.  (We use Scala notation; we explain non-standard aspects of the
language in footnotes.)  In each case, the synchronisation is mediated by a
\emph{synchronisation object}.

Perhaps the most common form of synchronisation object is a synchronous
channel.  Such a channel might have signature\footnote{The class is
  polymorphic in the type~{\scalashape A} of data.  The type {\scalashape
    Unit} is the type that contains a single value, the \emph{unit value},
  denoted~{\scalashape ()}.}
%
\begin{scala}
class SyncChan[A]{
  def send(x: A): Unit
  def receive(): A
}
\end{scala}
%
Each invocation of one of the operations must synchronise with an invocation
of the other operation: the two invocations must overlap in time.  If an
invocation |send(x)| synchronises with an invocation of |receive|, then the
|receive| returns~|x|.

Each synchronisation of a synchronous channel involves two invocations of
\emph{different} operations; we say that the synchronisation is
\emph{heterogeneous}.  By contrast, sometimes two invocations of the
\emph{same} operation may synchronise; we say that the synchronisation is
\emph{homogeneous}.  For example, an \emph{exchanger} has the following
signature.
%
\begin{scala}
class Exchanger[A]{
  def exchange(x: A): A
}
\end{scala}
%
When two threads call |exchange|, the invocations can synchronise, and each
receives the value passed in by the other.
%% When invocations of two different operations synchronise, we use the
%% term \emph{heterogeneous}; where two invocations of the same operation
%% synchronise, we use the term \emph{homogeneous}.  

For some synchronisation objects, synchronisations might involve more than two
threads.  For example, a \emph{barrier synchronisation} object of the
following class
%
\begin{scala}
class Barrier(n: Int){
  def sync(me: Int): Unit
}
\end{scala}
%
can be used to synchronise~|n| threads.  Each thread is assumed to have an
integer thread identifier in the range $\range{0}{\sm{n}}$.  Each thread~|me|
calls |sync(me)|, and no invocation returns until all~|n| have called it.  We
say that the synchronisation has \emph{arity}~|n|.

A \emph{combining barrier}, in addition to acting as a barrier
synchronisation, also allows each thread to submit a parameter, and for all to
receive back some function of those parameters.\footnote{The Scala type
  {\scalastyle (A,A) =}$>$ {\scalastyle A} represents functions from pairs of
  {\scalastyle A} to~{\scalastyle A}.}
%
\begin{scala}
class CombiningBarrier[A](n: Int, f: (A,A) => A){
  def sync(x: A): A
}
\end{scala}
%
The function |f| is assumed to be associative.  If |n| threads call |sync|
with parameters $x_1, \ldots, x_{\ss n}$, in some order, then each receives
back $\sm f(x_1, \sm f(x_2, \ldots \sm f(x_{{\ss n}-1}, x_{\ss n}) \ldots ))$.
(In the common case that |f| is commutative, this result is independent of the
order of the parameters.)

Some synchronisation objects allow different modes of synchronisation.  For
example, consider a synchronous channel with timeouts: each invocation might
synchronise with another invocation, or might timeout without
synchronisation.  Such a channel might have a signature as follows.
%
\begin{scala}
class TimeoutChannel[A]{
  def send(x: A): Boolean
  def receive(): Option[A]
}
\end{scala}
%
The |send| operation returns a boolean to indicate whether the send was
successful, i.e.~whether it synchronised.  The |receive| operation can return
a value |Some(x)| to indicate that it synchronised and received~|x|, or can
return the value |None| to indicate that it failed to synchronise\footnote{The
  type {\scalashape Option[A]} contains the union of such values.}.  Thus an
invocation of each operation may or may not synchronise with an invocation of
the other operation.  Equivalently, unsuccessful instances of send and receive
can be considered \emph{unary} synchronisations.  

So far, our example synchronisation objects have been \emph{stateless}: they
maintain no state from one synchronisation to another.  By contrast, some
synchronisation objects are \emph{stateful}: they maintain some state between
synchronisations, which might affect the availability of the results of
synchronisations.  As a toy example, consider a synchronous channel that, in
addition, maintains a sequence counter, and such that both invocations receive
the value of this counter.
\begin{scala}
class SyncChanCounter[A]{
  private var counter: Int
  def send(x: A): Int      // result is sequence number
  def receive(): (A, Int)  // result is (value received, sequence number)
}
\end{scala}

% Variations: homogenous case; different modes

Some implementations of synchronous channels allow the channel to be closed,
say by a unary operation |close|. 
\begin{scala}
class CloseableChan[A]{
  def send(x: A): Unit
  def receive(): A
  def close(): Unit
}
\end{scala} 
%
Calls to |send| or |receive| after the channel is closed throw an exception.
Thus such an object is stateful, with two states, open and closed; and the
operations have different modes of synchronisation, either successful or
throwing an exception.


An \emph{enrollable barrier} (based on~\cite{alting-barrier}) is a barrier
that allows threads to enrol and resign (via unary operations):
%
\begin{scala}
class EnrollableBarrier(n: Int){
  def sync(me: Int): Unit
  def enrol(me: Int): Unit
  def resign(me: Int): Unit
}
\end{scala} 
%
Each barrier synchronisation is between all threads that are currently
enrolled, so |sync| has a variable arity.  The barrier has a state, namely the
currently enrolled threads.

A \emph{terminating queue} can also be thought of as a stateful
synchronisation object with multiple modes.  Such an object acts like a
standard partial concurrent queue: if a thread attempts to dequeue, but the
queue is empty, it blocks until the queue becomes non-empty.  However, if a
state is reached where all the threads are blocked in this way, then they all
return a special value to indicate this fact.  In many concurrent algorithms,
such as a concurrent graph search, this latter outcome indicates that the
algorithm should terminate.  Such a terminating queue might have the
following signature, where a dequeue returns the value |None| to indicate the
termination case.
%
\begin{scala}
class TerminatingQueue[A](n: Int){ // £n£ is the number of threads   
  def enqueue(x: A): Unit
  def dequeue: Option[A]
}
\end{scala} 
%
The termination outcome can be seen as a synchronisation between all |n|
threads.  This terminating queue combines the functionality of a
concurrent datatype and a synchronisation object.


%% In general, a synchronisation will involve some number~$k$ of threads, calling
%% operations of the form
%% %
%% \begin{scala}
%%   def op£\s1£(x£\s1£: A£\s1£): B£\s1£
%%   ...
%%   def op£\s k£(x£\s k£: A£\s k£): B£\s k£
%% \end{scala}
%% %
%% Each thread passes in some data, and receives back a result. 

In this paper, we consider what it means for one of these synchronisation
objects to be correct.  We also present techniques for testing correctness of
implementations.

In Section~\ref{sec:spec} we describe how to specify a synchronisation object.
The definition has similarities with the standard definition of
\emph{linearisation} for concurrent datatypes, except it talks about
synchronisations between invocations, rather than single invocations: we call
the property \emph{synchronisation linearisation}; informally, the
synchronisations appear to take place in a one-at-a-time order, consistent
with the invocations of operations on the object.  We also define a progress
condition, which we call \emph{synchronisation progressibility}: informally,
invocations don't get stuck unnecessarily.

In Section~\ref{sec:relating} we consider the relationship between
synchronisation linearisation and (standard) linearisation.  We show that
linearisation is an instance of synchronisation linearisation, but that
synchronisation linearisation is more general.  We also show that
synchronisation linearisation corresponds to a small adaptation of
linearisation, where an operation of the synchronisation object may correspond
to \emph{two} operations of the object used to specify linearisation.

We then consider testing of synchronisation object implementations.  Our
techniques are based on the techniques for testing (standard)
linearisation~\cite{gavin:lin-testing}, which we sketch in
Section~\ref{sec:lin-testing}: the basic idea is to record a history of
threads using the object, and then to test whether that history is
linearisable.
%
In Section~\ref{sec:testing-hacking} we show how the technique can be adapted
to test for synchronisation linearisation, using the result of
Section~\ref{sec:relating}.  Then in Section~\ref{sec:direct} we show how
synchronisation linearisation can be tested more directly: we describe
algorithms that test whether a history of a synchronisation object is
synchronisation linearisable.  We also present various
complexity results: testing whether a history is synchronisation linearisable
is NP-complete in general, but can be solved in polynomial time in the case of
binary (heterogeneous or homogeneous) stateless synchronisation objects.

%% In Section~\ref{sec:modelChecking} we consider how the property of
%% synchronisation linearisation can be analysed via model checking.
%% \framebox{Cut this?} 

In Section~\ref{sec:experiments} we describe experiments to determine the
effectiveness of the testing techniques.  We sum up in
Section~\ref{sec:conc}. 

% \framebox{Contributions}
