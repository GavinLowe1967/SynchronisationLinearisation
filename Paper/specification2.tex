\subsection{Variations}
\label{ssec:spec-variations}

Above we considered heterogeneous binary synchronisations,
i.e.~synchronisations between \emph{two} executions of \emph{different}
operations, with a single mode of synchronisation.

It is straightforward to generalise to synchronisations between an arbitrary
number of operation executions, some of which might be executions of the same
operation.  Consider a $k$-way synchronisation between operations
\begin{scala}
def op£\s j£(x£\s j£: A£\s j£): B£\s j£   £for $j = 1, \ldots, k,$£
\end{scala}
%
where the $\op_j$ might not be distinct.
The specification object will have a corresponding operation
%
\begin{scala} 
def sync(x£\s1£: A£\s1£, ..., x£\s k£: A£\s k£): (B£\s1£, ..., B£\s k£)
\end{scala}
%
For example, for the combining barrier |CombiningBarrier(n, f)| of the
Introduction, the corresponding specification object would be
\begin{scala}
class CombiningBarrierSpec{
  def sync(x£\s1£: A, ..., x£\s{\ss n}£: A) = {
    val result = f(x£\s1£, f(x£\s2£,...f(x£\s{{\ss{n}}-1}£, x£\s{\ss n}£)...)); (result,...,result)
  }
}
\end{scala}

A history of the specification object will have corresponding events
$\sm{sync}^{i_1, \ldots, i_k}(x_1, \ldots, x_k)\:: (y_1, \ldots, y_k)$.
%
The definition of synchronisation linearisation is an obvious adaptation of
earlier: in the interleaving of the complete history of the synchronisation
history and the history of the specification object, each $\sm{sync}^{i_1,
  \ldots, i_k}(x_1, \ldots, x_k)\:: (y_1, \ldots, y_k)$ occurs between
$\call.\op_1^{i_j}(x_j)$ and $\return.\op_j^{i_j}\::y_j$ for each $j = 1,
\ldots, k$.  
%% The definition of synchronisation-linearisability follows in the obvious
%% way.

Note that if several of the $\op_j$ are the same operation, there is a choice
as to the order in which their parameters are passed to |sync|.  (However, in
the case of the combining barrier, if |f| is associative and commutative, the
order makes no difference.)

It is also straightforward to adapt the definitions to deal with multiple
modes of synchronisation: the specification object has a different operation
for each mode.  For example, recall the |TimeoutChannel| from the
Introduction, where sends and receives may timeout and return without
synchronisation.  The corresponding specification object would be:
%
\begin{scala}
class TimeoutChannelSpec[A]{
  def sync£\s s£(x: A) = false       // £send£ times out.
  def sync£\s r£(u: Unit) = None  // £receive£ times out.
  def sync£\s{s,r}£(x: A, u: Unit) = (true, Some(x))  // Synchronisation.
}
\end{scala}
%
The operation $\sm{sync}_s$ corresponds to a send returning without
synchronising; likewise $\sm{sync}_r$ corresponds to a receive returning
without synchronising; and $\sm{sync}_{s,r}$ corresponds to a send and receive
synchronising.  The formal definition of synchronisation linearisation is the
obvious adaptation of the earlier definition: in particular |sync|\s{s} must
occur between the call and return of a send that doesn't synchronise, and
likewise for |sync|\s{r}.

As another example, the following is a specification object for a channel with
a close operation.
%
\begin{scala}
class ClosableChannelSpec[A]{
  private var isClosed = false  // Is the channel closed? 
  def close(u: Unit) = { isClosed = true; () }
  def sync(x: A, u: Unit) = { require(!isClosed); ((), x) }
  def sendFail(x: A) = { require(isClosed); throw new Closed }
  def receiveFail(u: Unit) = { require(isClosed); throw new Closed }
}
\end{scala}
%
A send and receive can synchronise corresponding to |sync|, but only before
the channel is closed; or each may fail once the channel is closed,
corresponding to |sendFail| and |receiveFail|. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Specifying liveness}
\label{sec:progress}

We now consider a liveness condition for synchronisation objects.  

We assume that each pending operation execution is scheduled infinitely often,
unless it is blocked (for example, trying to obtain a lock); in other words,
the scheduler is fair to each execution.  Under this assumption, our liveness
condition can be stated informally as:
%
\begin{itemize}
\item If some pending operation executions can synchronise (according to the
  synchronisation specification object), then some such synchronisation should
  happen;

\item Once a particular execution has synchronised, it should eventually
  return.
\end{itemize}
%
Note that there might be several different synchronisations possible.  For
example, consider a synchronous channel, and suppose there are pending calls
to |send(4)|, |send(5)| and |receive|.  Then the |receive| could synchronise
with \emph{either} |send|, nondeterministically; subsequently, the |receive|
should return the appropriate value, and the corresponding |send| should also
return.  In such cases, our liveness condition allows \emph{either}
synchronisation to occur.
%
However, our liveness condition allows all pending executions to block if no
synchronisation is possible.  For example, if every pending executions on a
synchronous channel is a |send|, then clearly none can make progress.

Note that our liveness condition is somewhat different from the condition of
\emph{lock freedom} for concurrent datatypes~\cite{herlihy-shavit}.  That
condition requires that, assuming operation executions collectively are
scheduled infinitely often, then eventually some execution returns.  Lock
freedom makes no assumption about scheduling being fair.  For example, if a
particular thread holds a lock, then lock freedom allows the scheduler to
never schedule that thread; in most cases, this will mean that no operation
returns: any implementation that uses a lock in a non-trivial way is not
lock-free.

By contrast, our assumption, that each unblocked pending execution is
scheduled infinitely often, reflects that modern schedulers \emph{are} fair,
and do not starve any single execution.  For example, if a thread holds
a lock,  and is not in a potentially unbounded loop or permanently blocked
trying to obtain a second lock, then it will be scheduled sufficiently often,
and so will eventually release the lock.  Thus our liveness condition can be
satisfied by an implementation that uses locks.  

However, our assumption does allow executions to be scheduled in an
unfortunate order (as long as each is scheduled infinitely often), which may
cause the liveness condition to fail.  It also allows other synchronisation
primitives, such as locks and semaphores, to be unfair: for example, a thread
that is repeatedly trying to obtain a lock may repeatedly fail as other
threads obtain the lock.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The following definition identifies maximal sequences of synchronisations
that could occur given a particular history of a synchronisation object.
%
\begin{definition}
Given a history~$h$ of the synchronisation object and a legal history~$h_s$ of
the specification object, we say that $h_s$ is a \emph{maximal synchronisation
  linearisation} of~$h$ if:
\begin{itemize}
\item $h_s$ is a synchronisation linearisation of~$h$;

\item no proper legal extension $h_s \cat \trace{e}$ of~$h_s$ is a
  synchronisation linearisation of~$h$.
\end{itemize}
\end{definition}
%
% Note that a history may have multiple maximal synchronisation linearisations.
For example, the history 
\begin{eqnarray*}
h & = &\seq{\call.\send^1(4), \call.\send^2(5), \call.\receive^3(())}
\end{eqnarray*}
has two maximal synchronisation linearisations
\begin{eqnarray*}
h_s^1 & = &  \seq{\sync^{1,3}(4,())\::((),4)}, \\
h_s^2 & = & \seq{\sync^{2,3}(5,())\::((),5)},
\end{eqnarray*}
corresponding to the two possible synchronisations.  Each describes one
possibility for all the synchronisations that might happen. 

%%%%%

The following definition captures the $\return$ events that we would expect to
happen given a particular sequence of synchronisations.
%
\begin{definition}
Given a history~$h$ of the synchronisation object and a maximal
synchronisation linearisation~$h_s$, we say that a return event is
\emph{anticipated} if it does not appear in~$h$, but the corresponding $\sync$
event appears in~$h_s$.
\end{definition}
%
For example, considering the above histories~$h$ and~$h_s^1$, the events
$\return.\send^1\::()$ and $\return.\receive^3\::4$ are anticipated: assuming
$h_s^1$ describes the synchronisations that happen, we would expect those
$\return$ events to occur; if they do not, that is a failure of liveness.  

%%%%%

The following definition captures our fairness assumption.
%
\begin{definition}
Given an execution, we say 
%% that an operation execution is \emph{pending} if it
%% has been called but not yet returned.  We say 
that an operation execution is \emph{blocked} in a particular state if it is
unable to perform a step, for example because it is trying to acquire a lock
held by another thread, or waiting to receive a signal from another thread.

We say that an infinite execution is \emph{fair} if each pending operation
execution either (a)~eventually returns, (b)~is blocked in infinitely many
states, or (c)~performs infinitely many steps.  We consider a system execution
that reaches a deadlocked state (where every pending operation is permanently
blocked) to be infinite (it is infinite in time), and hence fair (under~(b)).
\end{definition}

The main reason we require fairness is to rule out executions where a thread
obtains a lock, but then is permanently descheduled, which could permanently
block other threads.  Modern schedulers are fair in this sense.

%%%%%

\begin{definition}
Let $h$ be a history of the synchronisation object.  We say that $h$ is
\emph{synchronisation progressible} if for every fair infinite execution
(following~$h$) with no new $\call$ events, there is a maximal synchronisation
linearisation~$h_s$ of~$h$ such that every anticipated return event~$ret$
eventually happens.
\end{definition}



%% Given a history~$h$ of the synchronisation object and a maximal
%% synchronisation linearisation~$h_s$, we say that $h$ is \emph{synchronisation
%%   progressible} with respect to~$h_s$ if for every anticipated return
%% event~$ret$, and for every fair infinite execution with no new $\call$ events,
%% $ret$ eventually happens.

%% We say that $h$ is \emph{synchronisation progressible} is there is some
%% maximal synchronisation linearisation~$h_s$ such that $h$ is synchronisation
%% progressible with respect to~$h_s$.
%% \end{definition}

For the earlier history~$h$, synchronisation progressibility
requires that either $\return.\send^1\::()$ and $\return.\receive^3\::4$
eventually happen (corresponding to~$h_s^1$), or $\return.\send^2\::()$ and
$\return.\receive^3\::5$ eventually happen (corresponding to~$h_s^2$): one of
the synchronisations should happen, and then the relevant operations should
return. 

On the other hand, for the history $\trace{\call.\send^1(4)}$, the only
maximal synchronisation linearisation is $\trace{}$, for which there are no
anticipated returns, and so synchronisation progressibility is trivially
satisfied: it is fine for the $\send$ to get stuck in this case, since there
is no $\receive$ with which it could synchronise.
