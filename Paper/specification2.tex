\subsection{Variations}
\label{ssec:spec-variations}

Above we considered heterogeneous binary synchronisations, i.e.~two
invocations of different operations, with a single mode of synchronisation.

It is straightforward to generalise to synchronisations between an arbitrary
number of invocations, some of which might be invocations of the same
operation.  Consider a $k$-way synchronisation between operations
\begin{scala}
def op£\s j£(x£\s j£: A£\s j£): B£\s j£   £for $j = 1, \ldots, k,$£
\end{scala}
%
where the $\op_j$ might not be distinct.
The specification object will have a corresponding operation
%
\begin{scala} 
def sync(x£\s1£: A£\s1£, ..., x£\s k£: A£\s k£): (B£\s1£, ..., B£\s k£)
\end{scala}
%
For example, for the combining barrier |CombiningBarrier(n, f)| of the
Introduction, the corresponding specification object would be
\begin{scala}
class CombiningBarrierSpec{
  def sync(x£\s1£: A, ..., x£\s{\ss n}£: A) = {
    val result = f(x£\s1£, f(x£\s2£,...f(x£\s{{\ss{n}}-1}£, x£\s{\ss n}£)...)); (result,...,result)
  }
}
\end{scala}

A history of the specification object will have corresponding events
$\sm{sync}^{i_1, \ldots, i_k}(x_1, \ldots, x_k)\:: (y_1, \ldots, y_k)$.
%
The definition of synchronisation linearisation is an obvious adaptation of
earlier: in the interleaving of the complete history of the synchronisation
history and the history of the specification object, each $\sm{sync}^{i_1,
  \ldots, i_k}(x_1, \ldots, x_k)\:: (y_1, \ldots, y_k)$ occurs between
$\call.\op_1^{i_j}(x_j)$ and $\return.\op_j^{i_j}\::y_j$ for each $j = 1,
\ldots, k$.  
%% The definition of synchronisation-linearisability follows in the obvious
%% way.

Note that if several of the $\op_j$ are the same operation, there is a choice
as to the order in which their parameters are passed to |sync|.  (However, in
the case of the combining barrier, if |f| is associative and commutative, the
order makes no difference.)

It is also straightforward to adapt the definitions to deal with multiple
modes of synchronisation: the specification object has a different operation
for each mode.  For example, recall the |TimeoutChannel| from the
Introduction, where sends and receives may timeout and return without
synchronisation.  The corresponding specification object would be:
%
\begin{scala}
class TimeoutChannelSpec[A]{
  def sync£\s s£(x: A) = false       // send times out
  def sync£\s r£(u: Unit) = None  // receive times out
  def sync£\s{s,r}£(x: A, u: Unit) = (true, Some(x))  // synchronisation
}
\end{scala}
%
The operation $\sm{sync}_s$ corresponds to a send returning without
synchronising; likewise $\sm{sync}_r$ corresponds to a receive returning
without synchronising; and $\sm{sync}_{s,r}$ corresponds to a send and receive
synchronising.  The formal definition of synchronisation linearisation is the
obvious adaptation of the earlier definition: in particular |sync|\s{s} must
occur between the call and return of send, and likewise for |sync|\s{r}.

As another example, the following is a specification object for a channel with
a close operation.
%
\begin{scala}
class ClosableChannelSpec[A]{
  private var isClosed = false  // is the channel closed? 
  def close(u: Unit) = { isClosed = true; () }
  def sync(x: A, u: Unit) = { require(!isClosed); ((), x)
  def sendFail(x: A) = { require(isClosed); throw new Closed }
  def receiveFail(u: Unit) = { require(isClosed); throw new Closed }
}
\end{scala}
%
A send and receive can synchronise corresponding to |sync|, but only before
the channel is closed; or each may fail once the channel is closed,
corresponding to |sendFail| and |receiveFail|. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Specifying progress}
\label{sec:progress}

We now consider a progress condition for synchronisation objects.  

We assume that each pending invocation is scheduled infinitely often, unless
it is blocked (for example, trying to obtain a lock); in other words, the
scheduler is fair to each invocation.  Under this assumption, our progress
condition can be stated informally as:
%
\begin{itemize}
\item If some pending invocations can synchronise (according to the
  synchronisation specification object), then some such synchronisation should
  happen;

\item Once a particular invocation has synchronised, it should eventually
  return.
\end{itemize}
%
Note that there might be several different synchronisations possible.  For
example, consider a synchronous channel, and suppose there are pending calls
to |send(4)|, |send(5)| and |receive|.  Then the |receive| could synchronise
with \emph{either} |send|, nondeterministically; subsequently, the |receive|
should return the appropriate value, and the corresponding |send| should also
return.  In such cases, our progress condition allows \emph{either}
synchronisation to occur.

Our progress condition allows all pending invocations to block if no
synchronisation is possible.  For example, if every pending invocations on a
synchronous channel is a |send|, then clearly none can return.

Note that our progress condition is somewhat different from the condition of
\emph{lock freedom} for concurrent datatypes~\cite{herlihy-shavit}.  That
condition requires that, assuming invocations collectively are scheduled
infinitely often, then eventually some invocation returns.  Lock freedom makes
no assumption about scheduling being fair.  For example, if a particular
invocation holds a lock then lock freedom allows the scheduler to never
schedule that invocation; in most cases, this will mean that no invocation
returns: any implementation that uses a lock in a non-trivial way is not
lock-free.

By contrast, our assumption, that each unblocked pending invocation is
scheduled infinitely often, reflects that modern schedulers \emph{are} fair,
and do not starve any single invocation.  For example, if an invocation holds
a lock, and is not in a potentially unbounded loop or permanently blocked
trying to obtain a second lock, then it will be scheduled sufficiently often,
and so will eventually release the lock.  Thus our progress condition can be
satisfied by an implementation that uses locks.  However, our assumption does
allow invocations to be scheduled in an unfortunate order (as long as each is
scheduled infinitely often), which may cause the progress condition to fail.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The following definitions identifies maximal sequences of synchronisations
that could occur given a particular history of a synchronisation object.
%
\begin{definition}
Given a history~$h$ of the synchronisation object and a history~$h_s$ of the
specification object, we say that $h_s$ is a \emph{maximal synchronisation
  linearisation} of~$h$ if:
\begin{itemize}
\item $h_s$ is a synchronisation linearisation of~$h$;

\item no proper extension $h_s \cat \trace{e}$ of~$h_s$ is a synchronisation
  linearisation of~$h$.
\end{itemize}
\end{definition}
%
% Note that a history may have multiple maximal synchronisation linearisations.
For example, the history 
\begin{eqnarray*}
h & = &\seq{\call.\send^1(4), \call.\send^2(5), \call.\receive^3(())}
\end{eqnarray*}
has two maximal synchronisation linearisations
\begin{eqnarray*}
h_s^1 & = &  \seq{\sync^{1,3}(4,())\::((),4)}, \\
h_s^2 & = & \seq{\sync^{2,3}(5,())\::((),5)},
\end{eqnarray*}
corresponding to the two possible synchronisations.  Each describes one
possibility for all the synchronisations that might happen. 

%%%%%

The following definition captures the $\return$ events that we would expect to
happen given a particular sequence of synchronisations.
%
\begin{definition}
Given a history~$h$ of the synchronisation object and a maximal
synchronisation linearisation~$h_s$, we say that a return event is
\emph{anticipated} if it does not appear in~$h$, but the corresponding $\sync$
event appears in~$h_s$.
\end{definition}
%
For example, considering the above histories~$h$ and~$h_s^1$, the events
$\return.\send^1\::()$ and $\return.\receive^3\::4$ are anticipated: assuming
$h_s^1$ describes the synchronisations that happen, we would expect those
$\return$ events to occur; if they do not, that is a failure of progress.  

%%%%%

The following definition captures our fairness assumption.
%
\begin{definition}
Given an execution, we say that an operation execution is \emph{pending} if it
has been called but not yet returned.  We say that an operation execution is
\emph{blocked} in a particular state if it is unable to perform a step, for
example because it is trying to acquire a lock held by another thread, or
waiting to receive a signal from another thread.

We say that an infinite execution is \emph{fair} if each pending operation
execution either (a)~eventually returns, (b)~is blocked in infinitely many
states, or (c)~performs infinitely many steps.  We consider a system execution
that reaches a deadlocked state (where every pending operation is permanently
blocked) to be infinite (it is infinite in time), and hence fair (under~(b)).
\end{definition}

The main reason we require fairness is to rule out executions where a thread
obtains a lock, but then is permanently descheduled, which could permanently
block other threads.  Modern schedulers are fair in this sense.

%%%%%

\begin{definition}
Let $h$ be a history of the synchronisation object.  We say that $h$ is
\emph{synchronisation progressible} if for every fair infinite execution
(following~$h$) with no new $\call$ events, there is a maximal synchronisation
linearisation~$h_s$ of~$h$ such that every anticipated return event~$ret$
eventually happens.
\end{definition}



%% Given a history~$h$ of the synchronisation object and a maximal
%% synchronisation linearisation~$h_s$, we say that $h$ is \emph{synchronisation
%%   progressible} with respect to~$h_s$ if for every anticipated return
%% event~$ret$, and for every fair infinite execution with no new $\call$ events,
%% $ret$ eventually happens.

%% We say that $h$ is \emph{synchronisation progressible} is there is some
%% maximal synchronisation linearisation~$h_s$ such that $h$ is synchronisation
%% progressible with respect to~$h_s$.
%% \end{definition}

For the earlier history~$h$, synchronisation progressibility
requires that either $\return.\send^1\::()$ and $\return.\receive^3\::4$
eventually happen (corresponding to~$h_s^1$), or $\return.\send^2\::()$ and
$\return.\receive^3\::5$ eventually happen (corresponding to~$h_s^2$): one of
the synchronisations should happen, and then the relevant operations should
return. 

On the other hand, for the history $\trace{\call.\send^1(4)}$, the only
maximal synchronisation linearisation is $\trace{}$, for which there are no
anticipated returns, and so synchronisation progressibility is satisfied: it
is fine for the $\send$ to get stuck in this case, since there is no
$\receive$ with which it could synchronise.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \subsection*{OLD VERSION}

%% The following definitions make this notion precise.
%% %
%% \begin{definition}
%% We say that an infinite execution is \emph{fair} if every invocation either
%% returns or performs infinitely many steps.

%% Consider a synchronisation object in a particular state~$st$.  We say that the
%% object \emph{eventually returns} if (1)~no execution leads to a deadlocked
%% state, and (2)~for every fair infinite execution
%% from~$st$ that contains no $\call$ event, there is a $\return$ event.
%% \end{definition}
%% %

%% The following definition describes the circumstances under which it is
%% acceptable for an object to block, and so does not eventually return.
%% %
%% \begin{definition}
%% \label{def:may-block}
%% Let $Sync$ be a synchronisation object that is synchronisation-linearisable
%% with respect to specification object $Spec$.  Let $h$ be a history of~$Sync$.
%% We say that $Sync$ \emph{may block} after~$h$ if there is a legal
%% history~$h_s$ of~$Spec$, such that:
%% %
%% \begin{itemize}
%% \item $complete(h)$ and~$h_s$ are compatible; and

%% \item There is no proper extension~$h'$ of~$h$ (adding one or more $\return$
%%   events, but no $\call$ events) and extension $h_s'$ of~$h_s$ such that
%%   $h_s'$ is a legal history of~$Spec$, and $complete(h')$ and~$h_s'$ are
%%   compatible.
%% \end{itemize}
%% \end{definition}
%% %
%% The first condition says that for each synchronisation in~$h_s$,
%% there is a corresponding $\return$ event in~$h$: there is no invocation that
%% has synchronised but not yet returned.  The second condition says that no more
%% synchronisations are possible: such a synchronisation would correspond to a
%% synchronisation event in~$h_s'$ and $\return$ event in~$h'$.

%% %%%%%

%% We give two examples, both for a synchronous channel.
%% %
%% \begin{example}
%% Consider $h = \seq{ \call.\send^1(3), \call.\receive^2(),
%%   \return.\receive^2\::3 }$.  Note that $h$ has a pending invocation, and
%% $complete(h) = \seq{\call.\receive^2(),\linebreak[1] \return.\receive^2\::3}$.
%% It is clear that there is no history~$h_s$ of~$Spec$ such that $complete(h)$
%% and~$h_s$ are compatible, because $complete(h)$ is missing the |send| invocation.
%% %
%% Definition~\ref{def:may-block} says that the channel may not block after~$h$.
%% Informally, a synchronisation has occurred, and so the pending return of the
%% |send| invocation should occur.
%% \end{example}

%% \begin{example}
%% Now consider $h = \seq{\call.\send^1(3), \call.\receive^2()}$.  We have that
%% $complete(h) = \seq{}$ is compatible with the history $h_s = \seq{}$ of $Spec$
%% (and no other). But the extension $h' = h \cat
%% \seq{\return.\send^1\::(),\linebreak[1] \return.\receive^2\::3}$ is compatible
%% with the extension $h_s' = \linebreak[1] \seq{\sync^{1,2}(3,()) \:: ((),3)}$
%% of~$h_s$.  Hence Definition~\ref{def:may-block} says that the channel may not
%% block after~$h$.  Informally, the two pending invocations can synchronise and
%% then return.
%% \end{example}

%% We now give an example where blocking is allowed.
%% %
%% \begin{example}  
%% Let $h = \seq{\call.\send^1(3)}$.  Then $complete(h) = \seq{}$ is compatible
%% with the history $h_s = \seq{}$ of $Spec$.  But the only proper extension
%% of~$h$ is $h' = \seq{\call.\send^1(3),\linebreak[1] \return.\send^1\::()}$,
%% and no history of $Spec$ is compatible with~$complete(h') = h'$.
%% \end{example}


%% \begin{definition}
%% Let $Sync$ be a synchronisation object that is synchronisation-linearisable
%% with respect to specification object $Spec$.  We say that $Sync$ is
%% \emph{synchronisation-progressable} if for every history~$h$, if it is not the
%% case that $Sync$ may block after~$h$, then, for every state reached
%% after~$h$,\, $Sync$ eventually returns.
%% \end{definition}
