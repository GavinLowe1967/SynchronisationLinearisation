\section{Experiments}
\label{sec:experiments}

In this section we describe experiments based on our testing framework. 

%%%%%

We consider synchronisation objects implementing a number of interfaces,
summarised in Figure~\ref{fig:examples}.  Most of the interfaces were
described in earlier sections (namely synchronous channel, filter channel,
exchanger, counter channel, barrier, enrollable barrier, timeout channel,
timeout exchanger, closeable channel, and terminating queue).


\begin{figure}
\begin{center}
\begin{tabular}{lccc}
Category            & Arity & Stateful? & Heterogeneous? \\ \hline
Synchronous channel & 2     & N         & Y \\
Filter channel      & 2     & N         & Y \\
Men and women        & 2     & N         & Y \\
Exchanger           & 2     & N         & N \\
Counter channel     & 2     & Y         & Y \\
Two families        & 2     & Y         & Y \\
One family          & 2     & Y         & N \\
ABC                 & 3     & N         & Y \\
Barrier             & $n$   & N         & N \\
Enrollable barrier  & $1\mathord{..} n$, 1 & Y & N \\
Timeout channel     & 2, 1  & N         & Y \\
Timeout exchanger   & 2, 1  & N         & N \\
Closeable channel   & 2, 1  & Y         & Y \\
Terminating queue   & 1, $n$ & Y        & N  
\end{tabular}
\end{center}
\caption{Example interfaces of synchronisation objects.  \label{fig:examples}}
\end{figure}

% Channel with counter & 2    & Y         & Y \\
% ABC with counter    & 3     & Y         & Y \\
% Barrier with counter & $n$  & Y         & N \\   
% Add combining barrier?    

%%%%%

%
The \emph{men and women} problem involves two families of threads, known as
men and women: each thread wants to pair off with a thread of the other type;
each passes in its own identity, and expects to receive back the identity of
the thread with which it has paired.  
%
In the \emph{two families} problem, there are two families of threads, with
$n$~threads of each family; each thread calls an operation~$n$ times, and each
execution should synchronise with a thread of the opposite family, but with a
\emph{different} thread each time.  In the \emph{one family} problem, there
are $n$~threads, each of which calls an operation $n-1$~times, and each time
should synchronise with a \emph{different} thread.
%
Finally, the \emph{ABC} problem can be thought of as a ternary version of the
men and women problem: there are three types of threads, A, B and C; each
synchronisation involves one thread of each type.
%
%% Finally, the \emph{timeout exchanger} is a timed version of the exchanger: if
%% a thread fails to exchange data with another thread, it can timeout and return
%% an appropriate result.

For each interface, we have implemented a tester using the two-step approach
from Section~\ref{sec:lin-testing}, and also a tester using the direct
algorithm from Section~\ref{sec:direct}.

For each interface, we have produced a correct implementation.  Most
implementations are quite short, about 30 lines of code on average.  An
exception is the implementation of a synchronous channel from the SCL
library~\cite{gavin:SCL-CSP} (which supports closing, timeouts and
alternation), which is a few hundred lines.  However, as noted in the
Introduction, despite most implementations begin quite short, they can be hard
to get right.

For most interfaces, we have also implemented one or more faulty versions that
fail to achieve either synchronisation linearisation or progressibility.  The
faulty versions mostly have realistic mistakes: a few are genuine bugs; others
are similar to bugs we have seen from students.  Some of the bugs are caused
by an operation failing to wait for the previous synchronisation to finish,
which can lead to interference between the two synchronisations.  Other bugs
allow threads to run in an unexpected order (because of unfortunate
scheduling), which falsifies the intended logic.  A particularly subtle bug
concerns a previous implementation of the channel in SCL: here, if three
threads run concurrently, one sending, one receiving, and one closing the
channel, it is possible for the receiver to return as if it has synchronised,
then for the closing to take effect, and then for the receiver to find the
channel closed and signal a failure; this is an error, since either both
threads should think they synchronised, or neither.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{Experiments}

We describe various experiments below.  The purpose of testing is to find
bugs.  We therefore concentrate on the time taken to find bugs.  If the
technique is fast to find bugs when they exist, then the failure to find bugs
on other examples should give us reasonable confidence that none exists.

We consider the following questions.
\begin{itemize}
\item Which works better, the direct algorithm or the two-step algorithm?  The
  experiments show that the direct algorithms are faster in most cases.
  Further, the direct algorithms scale much better as the number of operation
  executions per run increases.

\item How should we choose parameters (number of threads to run, number of
  iterations performed by each thread, etc.)\ for testing?  The experiments
  suggest that, for both types of tester, it is best to use a  small
  number of threads (typically two to four), each performing a small number of
  operations (typically about four).    

\item Is this approach effective at finding bugs?  The experiments suggest it
  is.  For each of the incorrect examples we considered, each approach found
  an error for synchronisation linearisation within about a second on average,
  and somewhat faster on most examples.  For synchronisation progressibility,
  they were typically a few hundred milliseconds slower.
\end{itemize}

%% Questions we want to answer include:
%% \begin{itemize}
%% \item Which works better, the direct algorithm or the two-step algorithm?  
%% \item How should we choose parameters (number of threads to run, number of
%%   iterations performed by each thread, etc.)\ for testing?  
%% \item Is this approach effective at finding bugs?
%% \end{itemize}

The experiments were performed on a dedicated eight-core machine (two 2.40GHz
Intel(R) Xeon(R) E5620 CPUs, with 12GB of RAM, but limited to 4GB of heap
space).

In each experiment below, we consider a synchronisation object with a bug that
causes a failure of synchronisation linearisation, but does not lead to a
deadlock.  We performed a number of \emph{runs} of a tester on the
synchronisation object.  In each run, a particular number of threads performed
a particular number of operation calls on the synchronisation object; the
relevant algorithm was then used to decide whether the log history was
synchronisation linearisable or two-step linearisable.

Each \emph{observation} performed multiple runs until an error was detected,
and recorded the time taken.  Each observation was performed as a separate
operating system process, with the aim of making observations independent,
avoiding dependencies caused by, for example, garbage collection, caching
behaviour, and just-in-time compilation.  Thus each observation was as close
as possible to a normal use case.

For each data point in the experiments, we performed 100 observations.  We
give the average time to find an arror, and a 95\%-confidence interval for
that average (following~\cite{GBE2007}).  The number of observations is chosen
so as to obtain a reasonably small confidence interval, but avoiding
excessively long experiments.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We start with the second of the questions above, how to choose parameters for
testing.  Each of the graphs in Figures~\ref{fig:params-experiment-1}
and~\ref{fig:params-experiment-2} concerns a particular tester.  Each data
point represents a particular number $p$ of worker threads (given in the key),
and a particular number of operation executions per run by each thread (given
on the $X$-axis).
%, with 100 observations.  
The $Y$-axis gives the time in milliseconds.  (The graph for the two-step
tester applied to a barrier omits a plot for $p = 10$, with times of around
5000ms, which does not fit on the axes.)

%scala -cp .:/home/gavin/Scala/Util  experiments.BugParametersExperiment --doAll --samples 100
\input{BPNall}

The experiments suggest that both types of tester work best with a fairly
small number of worker threads (typically two to four), each performing a
fairly small number of operations per run (typically about four).

Some bugs are exhibited only when the number of threads exceeds the arity of a
synchronisation: for example, in the ABC problem, two different
synchronisations interfere to produce the error.
%% ; for the closeable channel, the closing of the channel interferes
%% with a synchronisation.
We therefore recommend including enough threads to
find such bugs.

On the other hand, the number of operations performed by each thread should
not be too small.  For example, for the ABC problem, the testers are rather
slow to find the bug when each thread performs only two operations per run.
The reason in this case seems to be that on most runs some of the threads
finish their operations before others start, which removes the possibility of
interference between synchronisations.

Using rather short runs has an additional advantage: if the tester does find
an erroneous history, a shorter history is normally easier to interpret than a
longer one.  

%%  We therefore subsequently run four threads for binary
%% synchronisation objects, or six for the ABC problem (where the tester assumes
%% the number of threads is divisible by~three).  A barrier is of a different
%% nature, since it synchronises all the threads; but we again subsequently run
%% four threads on barriers.  In each of these cases, we arrange for each thread
%% to execute four operations.  An exception is the exchanger: as explained
%% earlier, we arrange for each thread to perform a single 

%%%%%%%%%%

The results also suggest that the direct algorithms scale better than the
two-step tester as the number of threads increases.
Figure~\ref{fig:scalingExperiment} investigates this further.  Each graph
considers one type of synchronisation object, with the two plots representing
the two testers.  Each data point considers a particular number of threads
(given on the $X$-axis).
%, with 100 observations.  
The $Y$-axis again gives the time in milliseconds.  We omit results for cases
where the two-step tester sometimes ran out of memory.

% scala -cp .:/home/gavin/Scala/Util  experiments.BugParametersExperiment --scalingExperiments --samples 100
\input{scalingExperiment}

%
The results confirm that the two-step approach does not scale well with the
number of threads.  In each case, the running time increases dramatically at a
particular point, and tests often fail.  The running time also becomes erratic
(as indicated by the wide confidence intervals): some runs take an extremely
long time.  By contrast, the direct algorithms scale well.

We believe the reason the two-step approach scales poorly is as follows.  The
linearisation tester tries to find a linearisation order for operation
executions, via a depth-first search.  At each step, it picks a particular
operation execution to try to linearise next.  If it picks wrongly, it might
have to consider many nodes of the search graph before backtracking.  This can
be the case with two-step testing, because if it picks the wrong $\op_1$ to try
to linearise, it will only discover this fact when it reaches the
corresponding $\overline{\op}_1$ and finds the wrong value is returned.  This
latter event might be much later in the history.  To reach it, the tester has
to consider many possibilities for ordering other operation executions.

%%%%%%%%%%

Figure~\ref{fig:bugFindingExperiment} gives times to find various bugs with
the two testers.  Based on the earlier experiments, in most cases we ran four
threads, each executing four operations; for the ABC testers, we ran six
threads, each executing four operations; for the (untimed) exchanger, we ran
eight threads, each performing a single operation (recall from
Section~\ref{sec:relating} that this avoids deadlocks); for the two-families
object, we ran four threads (two from each family), each performing two
operations; and for the one-family object, we ran four threads, each
performing three operations.  The table gives average times in milliseconds to
detect the bug, with 95\%-confidence intervals.

%%%%%

\begin{figure}
%scala -cp .:/home/gavin/Scala/Util  experiments.BugFinderExperiment --samples
%100
\begin{center}
\begin{tabular}{lr@{$\,\pm\,$}lr@{$\,\pm\,$}l}
Synchronisation object & \multicolumn{2}{c}{Direct} &
\multicolumn{2}{c}{Two-step} \\ \hline
Synchronous channel  &	85 	 & 3 &  	109	 & 2 \\
Filter channel &        77       & 1 &          108      & 3 \\
%\multicolumn{2}{c}{---} & \multicolumn{2}{c}{---} \\
Men and women  &	75	 & 1 &  	108	 & 4 \\
Exchanger  	&       73	 & 1 &  	511	 & 25 \\
Counter channel &  	94	 & 2 &  	106	 & 1 \\
Two families &  	299	 & 34 &  	267	 & 25 \\
One family &    	336	 & 27 &         437      & 39 \\
% \multicolumn{2}{c}{---} \\
ABC &    	        717	 & 225 &  	928	 & 216 \\
Barrier &       	80	 & 1 &   	106	 & 1 \\
Enrollable barrier &  	132	 & 5 &  	149	 & 6 \\
Timeout channel  &	121	 & 5 &  	135	 & 5 \\
Timeout exchanger & 	288	 & 64 &  	231	 & 18 \\
Closeable channel & 	191	 & 11 &  	173	 & 9 \\
Terminating queue & 	103	 & 1 &  	105	 & 1
\end{tabular}
\end{center}
%\framebox{???} Add one family, filter channel? % Remove counter channel? 
\caption{Times to find bugs affecting synchronisation linearisation.}
\label{fig:bugFindingExperiment}
\end{figure}

%%%%%

All the testers work well, with the average time to find each bug below one
second.  Of course, other bugs might be harder to find, because they are
triggered on fewer runs.  However, our results do suggest that our techniques
are effective at finding most bugs.

In most cases, the direct tester is faster than the two-step one; and the
two-step tester is never significantly faster.  We therefore recommend the
direct algorithms.  This approach has two additional advantages.  Our
experience is that it is easier to create the testing program based on the
direct algorithms, whereas using the two-step approach involves designing and
encoding the appropriate automaton, which can be somewhat tricky.  Further,
error histories found by the direct algorithms tend to be easier to
understand: the corresponding two-step history is longer, because of the
second step of some operations, and this can be distracting.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We now consider synchronisation progressibility.  Our experience is that if a
synchronisation object does not satisfy progressibility, then this can lead to
a total deadlock.  Thus, in most cases, testing for synchronisation
linearisability will also detect progressibility bugs.  However, this is no
guarantee.    

%% We also carried out some experiments to assess the throughput on correct
%% implementations when testing for progressibility.  However, the times were
%% dominated by the times waiting for timeouts.  Where there were differences
%% between examples, these simply reflect the probability of the system
%% completing on its own, and not having to wait for the timeout.  We omit the
%% results, because they are uninteresting.

% \framebox{Add experiments?}

Recall that our approach is to interrupt threads after a suitable duration.
This duration should be chosen so that if any threads have not returned by
this point, then (almost certainly) they really are stuck.  Our informal
experiments suggest that a duration of 100ms is appropriate (at least, on the
architecture we were using): we have not observed any false positives with
this duration, but did with a shorter duration of 80ms.  If an error is found
(and the cause is not immediately apparent), it is straightforward to increase
the duration and see whether the error still occurs.  Of course, a larger
value for this duration does increase the time that a given number of runs
will take: a tester may take the view that it's easiest to use a larger
duration, and just leave the tests running for longer.


\begin{figure}
\begin{center}
% scala -cp .:/home/gavin/Scala/Util  experiments.BugFinderExperiment --progressCheck 100  --samples 100
\begin{tabular}{lr@{$\,\pm\,$}l}
% Synchronisation object & \multicolumn{2}{c}{Direct}\\ \hline
Synchronous channel  &	323	 & 39 \\
Filter channel  &	338	 & 50 \\
Men and women  	&       232	 & 19 \\
One family  	&      1098	 & 278 \\
ABC  	&              1080	 & 186 \\
Barrier  	&       169	 & 3
\end{tabular}
\end{center}
\caption{Times to find bugs affecting synchronisation progressibility.}
\label{fig:progressBugFindingExperiment}
\end{figure}

Figure~\ref{fig:progressBugFindingExperiment} gives results for the time to
find various bugs that lead to a failure of progressibility.  Each uses the
relevant direct algorithm: recall that two-step linearisation cannot be used
to test progressibility. 

Again, each bug is found quickly, within about a second.  Testing for
progressibility is normally a bit slower than for linearisation, because of
the need to interrupt the worker threads, but only after allowing enough time
that we can be confident that they really have got stuck.

One class of errors that we believe our testing framework will be less
successful at finding is so-called \emph{spurious wake-ups}.  Scala inherits a
wait/notify mechanism from Java.  A thread that calls |wait()| is supposed to
suspend until another thread calls |notify()|.  Unfortunately, a waiting
thread may spuriously wake-up and continue without being notified.
Programmers are expected to guard against spurious wake-ups --- but sometimes
they don't, and this leads to bugs.  However, spurious wake-ups happen
sufficiently rarely that they might not be found by testing in a reasonable
amount of time.
