\section{Direct testing of synchronisation linearisation and progressability}
\label{sec:direct}

We now consider how to test for synchronisation linearisation more directly.
We perform logging precisely as for standard linearisation: a thread that
performs a particular operation~$\sm{op}^i(x)$: (1) writes
$\call.\sm{op}^i(x)$ into the log; (2)~performs $\sm{op}(x)$ on the
synchonisation object, obtaining result~$y$, say; (3)~writes
$\return.\sm{op}^i \:: y$ into the log.  

When testing for synchronisation linearisation, we again make it the
responsibility of the tester to define the worker threads in a way that
ensures that all operation executions will be able to synchronise, so all
threads will eventually terminate. 
%%  For example, for a binary heterogeneous synchronisation object, threads
%% collectively should perform the same number of each operation.

When testing for progress, we remove the requirement on the tester to ensure
that all operation executions can synchronise.  Indeed, in some cases, in
order to find failures of progress, it is necessary that not all executions
can synchronise: we have examples of incorrect synchronisation objects where
(for example) if there are two executions of $\op_1$ and one of~$\op_2$, then
it's possible that \emph{neither} execution of~$\op_1$ returns, signifying
a failure of progressability; but if there were a second execution
of~$\op_2$, it would unblock both executions of~$\op_1$, so all executions
would return, and the failure of progressability would be missed.

Instead, we run threads performing operations, typically chosen at random; and
after a suitable duration, we interrupt any threads that have not yet
returned.  The duration before the interrupts needs to be chosen so that it is
highly likely that any threads that have not returned really are stuck:
otherwise this approach it likely to produce false positives.  Our informal
experiments suggest that a duration of 100ms is appropriate (at least, on the
architecture we were using): we have not observed any false positives with
this duration, but did with a shorter duration of 80ms.  This delay does
significantly increase the time that a given number of runs will take.


In the remainder of this section we consider algorithms for determining if the
resulting log history is synchronisation linearisable, and whether it is
synchronisation progressable.  In Section~\ref{sec:algorithm-dfs} we present a
general algorithm for this problem, based on depth-first search.  We then
consider the complexity of this problem.  We show, in
Section~\ref{sec:NP-complete}, that, in the case of a stateful synchronisation
object, the problem of deciding whether a history is synchronisation
linearisable is NP-complete in general.  However, we show that in the case of
binary synchronisations with a stateless specification object the problem can
be solved in polynomial time: we consider the heterogeneous case in
Section~\ref{sec:binary-heterogeneous}, and the homogeneous case in
Section~\ref{sec:binary-homogeneous}.  Nevertheless, in
Section~\ref{sec:non-binary-stateless} we show that for synchronisations of
three or more executions, the problem is again NP-complete, even in the
stateless case.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The general case}
\label{sec:algorithm-dfs}

We describe an algorithm for deciding whether a given complete history~$h$ is
synchronisation linearisable with respect to a given synchronisation
specification object.  We transform the problem into a graph-search algorithm
as follows.

We define a search graph, where each node is a \emph{configuration}
comprising:
%
\begin{itemize}
\item An index $i$ into the log;

\item A set $pending$ of operation executions that were called in the
  first~$i$ events of the log and that have not yet been linearised;

\item A set $linearised$ of operation executions that were called in the
  first~$i$ events of the log and that have been linearised, but have not yet
  returned;

\item The state $spec$ of the specification object after the synchronisations
  linearised so far.
\end{itemize}
%
From such a configuration, there are edges to configurations as follows:
%
\def\edgeFont#1{\rm\textsf{#1}}
\begin{description}
\item[\edgeFont{Synchronisation}.] If some set of executions in $pending$ can
  synchronise, giving results compatible with~$spec$, then there is an edge to
  a configuration where the synchronising executions are moved into
  $linearised$, and $spec$ is updated corresponding to the synchronisation;

\item[\edgeFont{Call}.] If the next event in the log is a $\call$ event, then
  there is an edge where that event is added to $pending$, and $i$ is
  advanced;

\item[\edgeFont{Return}.] If the next event in the log is a $\return$ event,
  and the corresponding execution is in $linearised$, then there is an edge
  where that execution is removed from $linearised$, and $i$ is advanced.
\end{description}
%
The initial configuration has $i$ at the start of the log, $pending$ and
$linearised$ empty, and $spec$ the initial state of the specification object.
Target configurations have $i$ at the end of the log, and $pending$ and
$linearised$ empty.

Any path from the initial configuration to a target configuration clearly
represents an interleaving of a history of the specification object with~$h$,
as required for synchronisation linearisation.  We can therefore search this
graph using a standard algorithm.  Our implementation uses depth-first search.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsubsection{Progress}

It is straightforward to adapt the search algorithm to also test for progress.
We change the definition of a target configuration to have $i$ at the end of
the log, $linearised$ empty, and such that no set of executions in $pending$
can synchronise: this ensures that we are dealing with a \emph{maximal}
synchronisation linearisation.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Partial-order reduction}

We have investigated a form of partial-order reduction, which we call
\emph{ASAP linearisation}.  The idea is that we try to linearise executions
\emph{as soon as possible}.
%
\begin{definition}
Let $h$ be a complete history of a synchronisation object, and let~$h_s$ be a
legal history of the corresponding specification object; and consider an
interleaving, as required for synchronisation linearisation.  We say that the
interleaving is an \emph{ASAP interleaving} if every event in~$h_s$ appears
either: (1)~directly after the $\call$ event of one of the corresponding
executions from~$h$; or (2)~directly after another event from~$h_s$.
\end{definition}
%
The following lemma shows that it suffices to consider ASAP interleavings.
%
\begin{lemma}
Let $h$ be a complete history of a synchronisation object, and let~$h_s$ be a
legal history of the corresponding specification object.  If $h_s$ is a
synchronisation linearisation of~$h$, then there is an ASAP interleaving of
them.
\end{lemma}
%
\begin{proof}
Consider an interleaving of~$h$ and~$h_s$, as required for synchronisation
linearisation.  We transform it into an ASAP interleaving as follows.  Working
forwards through the interleaving, we move every event of $h_s$ earlier in the
interleaving, as far as possible, without it moving past any of the corresponding
$\call$ events, nor moving past any other event from~$h_s$.  This means that
subsequently each such event follows either a corresponding $\call$ event or
another event from~$h_s$.

Note that each event from~$h_s$ is still between the $\call$ and $\return$
events of the corresponding executions.  Further, we do not reorder events
from~$h_s$ so the resulting interleaving is still an interleaving of~$h$
and~$h_s$.

Thus the resulting interleaving is an ASAP interleaving.
\end{proof}
%
Our approach, then, is to trim the search graph by removing
\edgeFont{synchronisation} edges that do not correspond to an ASAP
linearisation: after a \edgeFont{call} edge, we attempt to linearise a
synchronisation corresponding to that call, and then, if successful, to
linearise an arbitrary sequence of other synchronisations; but we do not
otherwise allow synchronisations.

Our experience is that this tactic is moderately successful.  In some cases,
it can reduce the total time to check histories by over~30\%;
although in some cases the gains are smaller, sometimes negligible.  The gains
seem highest in examples where there can be a reasonably large number of
pending executions.
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Complexity}
\label{sec:NP-complete}

Consider the problem of testing whether a given concurrent history is
synchronisation linearisable with respect to a given synchronisation
specification object.  We show that this problem is NP-complete in general.

We make use of a result from~\cite{gibbons-korach} concerning the complexity
of the corresponding problem for linearisability.  Let |Variable| be a
linearisability specification object corresponding to an integer variable with
|get| and |set| operations.  Then the problem of deciding whether a given
concurrent history is linearisable with respect to |Variable| is NP-complete.

Since standard linearisation is a special case of synchronisation
linearisation (in the trivial case of unary synchronisations), this
immediately implies that deciding synchronisation linearisation is
NP-complete.  However, even if we restrict to the non-trivial case of binary
synchronisations, the result still holds.
%
We consider concurrent synchronisation histories on an object with the
following signature, which mimics the behaviour of a variable but via
synchronisations. 
%
\begin{scala}
object VariableSync{
  def op£\s1£(op: String, x: Int): Int
  def op£\s2£(u: Unit): Unit
} 
\end{scala}
%
The intention is that |op|\s1|("get", x)| acts like |get(x)|, and
|op|\s1|("set", x)| acts like |set(x)| (but returns -1).  The |op|\s2
operation does nothing except synchronise with~|op|\s1.  This
can be captured formally by the following synchronisation specification
object.
%
\begin{scala}
object VariableSyncSpec{
  private var state = 0   // the value of the variable
  def sync((op, x): (String, Int), u: Unit): (Int, Unit) = 
    if(op == "get") (state, ()) else{ state = x; (-1, ()) }
}
\end{scala}

Let |ConcVariable| be a concurrent object that represents an integer variable.
Given a history~$h$ of |ConcVariable|, we build a history~$h'$ of
|VariableSync| as follows.  We replace every call or return of |get(x)| by
(respectively) a call or return of |op|\s1|("get", x)|; and we do similarly
with |set|s.  If there are $k$ calls of |get| or |set| in total, we prepend
$k$ calls of |op|\s2, and append $k$ corresponding returns (in any order).
%
Then it is clear that $h$ is linearisable with respect to |Variable| if and
only if $h'$ is linearisable with respect to |VariableSyncSpec|.  Deciding the
former is NP-complete; hence the latter is also. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The binary heterogeneous stateless case}
\label{sec:binary-heterogeneous}

The result of the previous subsection used a \emph{stateful} specification
object.  We now consider the \emph{stateless} case.  We show that for binary
heterogeneous synchronisations, the problem of deciding whether a history is
synchronisation linearisable can be decided in quadratic time.  We consider
the homogeneous case in the next subsection.

So consider a binary heterogeneous synchronisation object, whose specification
object is stateless.  Note that in this case we do not need to worry about the
order of synchronisations: if each individual synchronisation is correct, then
any permutation will also be correct from the point of view of the
specification object; and we can order the synchronisations in a way that is
compatible with the concurrent history.  Informally, the idea is to find
matching operation executions in the concurrent history that could correspond
to a particular synchronisation; we therefore reduce the problem to that of
finding a matching in a graph.

Define two complete operation executions to be \emph{compatible} if they could
be synchronised, i.e.~they overlap and the return values agree with those for
the specification object.  For $n$ executions of operations this can be
calculated in $O(n^2)$.

Consider the bipartite graph where the two sets of nodes are executions
of~$\op_1$ and~$\op_2$, respectively, and there is an edge between two
executions if they are compatible.  A synchronisation linearisation then
corresponds to a total matching of this graph: given a total matching, we
build a synchronisation linearisation by including events
$\sync^{i_1,i_2}(x_1,x_2)\::(y_1,y_2)$ (in an appropriate order) whenever
there is an edge between $\op_1^{i_1}(x_1)\::y_1$ and $\op_2^{i_2}(x_2)\::y_2$
in the matching; and conversely, each synchronisation linearisation
corresponds to a total matching.

Thus we have reduced the problem to that of deciding whether a total matching
exits, for which standard algorithms exist.  We use the Ford-Fulkerson
method~\cite{ford-fulkerson}, which runs in time $O(n^2)$.

It is straightforward to extend this to a mix of binary and unary
synchronisations, again with a stateless specification object: the executions
of unary operations can be considered in isolation.  

This approach can be easily extended to also test for progress.  It is enough
to additionally check that no two pending executions could synchronise.

%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The binary homogeneous stateless case}
\label{sec:binary-homogeneous} 

We now consider the case of binary \emph{homogeneous} synchronisations with a
stateless specification object.  This case is almost identical to the case
with heterogeneous synchronisations, except the graph produced is not
necessarily bipartite.  Thus we have reduced the problem to that of finding a
maximum matching in a general graph.  This problem can be solved using, for
example, the blossom algorithm~\cite{edmonds_1965}, which runs in time
$O(n^4)$.
  
% Can also be done in time $O(n^{2.5})$.
%\verb!https://en.wikipedia.org/wiki/Maximum_cardinality_matching!

%We haven't implemented this. 

In fact, our experiments use a simpler algorithm.  We attempt to find a
matching via a depth-first search: we pick a node~$n$ that has not yet been
matched, try matching it with some unmatched compatible node~$n'$, and recurse
on the remainder of the graph; if that recursive search is unsuccessful, we
backtrack and try matching~$n$ with a different node.  We guide this search by
the standard heuristic of, at each point, expanding the node~$n$ that has
fewest unmatched compatible nodes~$n'$.  

In our only example of this category, the |Exchanger| from the Introduction,
we can choose the values to be exchanged randomly from a reasonably large
range (say size~100).  Then we can nearly always find a node~$n$ for which
there is a unique unmatched compatible node: this means that the algorithm
nearly always runs in linear time.  We expect that similar techniques could be
used in other examples in this category.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The non-binary stateless case}
\label{sec:non-binary-stateless}

It turns out that for synchronisations of arity greater than~2, the problem of
deciding whether a history is synchronisation linearisable is NP-complete in
general, even in the stateless case.  We prove this fact by reduction from the
following problem, which is known to be NP-complete~\cite{Karp1972}.
%
\begin{definition}
The problem of finding a complete matching in a 3-partite hypergraph is as
follows: given disjoint finite sets $X$, $Y$ and~$Z$ of the same cardinality,
and a set $T \subseteq X \times Y \times Z$, find $U \subseteq T$ such that
each member of~$X$, $Y$ and~$Z$ is included in precisely one element of~$T$.
\end{definition}

Suppose we are given an instance $(X, Y, Z, T)$ of the above problem.  We
construct a synchronisation specification and a corresponding history~$h$ such
that $h$ is synchronisation linearisable if and only if a complete matching
exists.  The synchronisations are between operations as follows:
\begin{scala}
  def op£\s1£(x: X): Unit
  def op£\s2£(y: Y): Unit
  def op£\s3£(z: Z): Unit
\end{scala}
%
The synchronisations are specified by:
%
\begin{scala}
  def sync(x: X, y: Y, z: Z): (Unit, Unit, Unit) = {
    require(£$(\sm x, \sm y, \sm z) \in T$£); ((), (), ())
  }
\end{scala}
%
The history~$h$ starts with calls of |op|$_1(x)$ for each $x \in X$,
|op|$_2(y)$ for each $y \in Y$, and |op|$_3(z)$ for each $z \in Z$ (in any
order); and then continues with returns of the same executions (in any
order).  It is clear that any synchronisation linearisation corresponds to a
complete matching, i.e.~the executions that synchronise correspond to the
complete matching~$U$.  Hence finding a synchronisation linearisation is
NP-complete. 

Our implementation for these cases uses a depth-first search to find a
matching, very much like in the binary homogeneous case.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Implementation}

We have implemented a testing framework (in Scala), based on the above
algorithms, and used it to implement testers for particular synchronisation
objects\footnote{The implementation is available from ???.}.  We consider the
framework to be straightforward to use: most of the boilerplate code is
encapsulated within the framework; defining a tester for a new synchronisation
object takes just a few minutes.

Figure~\ref{fig:ChanTester} gives a stripped-down tester for a synchronous
channel.  (The full version can be used to test a number of implementations
with the same interface, and replaces the numeric constants by parameters that
can be set on the command line.)

%%%%%

\begin{figure}
\begin{scala}
object ChanTester extends Tester{
  trait Op   // Representation of operations within the log
  case class Send(x: Int) extends Op
  case object Receive extends Op

  def worker(c: SyncChan[Int])(me: Int, log: HistoryLog[Op]) = 
    for(i <- 0 until 20)
      if(me%2 == 0) log(me, c.receive(), Receive)
      else{ val x = Random.nextInt(100); log(me, c.send(x), Send(x)) }

  object SyncChanSpec{
    def sync(x: Int, u: Unit) = ((), x)    
  }

  def matching: PartialFunction[(Op,Op), (Any,Any)] = {
    case (Send(x), Receive) => SyncChanSpec.sync(x, ()) // = ((), x)
  }

  /** Do a single test.  Return true if it passes. */
  def doTest(): Boolean = {
    val c = new SyncChan[Int]
    new BinaryStatelessTester[Op](worker(c), 8, matching)()
  }

  def main(args: Array[String]) = {
    var i = 0; while(i < 5000 && doTest()) i += 1
  }
}
\end{scala}
\caption{A simple tester for a synchronous channel. \label{fig:ChanTester}}
\end{figure}

%%%%%%%%%%

The |worker| function defines a worker thread that performs operations on the
channel~|c|.  The function also takes parameters representing the thread's
identity and a log object.  Here, each worker with an even identity performs
20 |receive| executions: the call |log(me, c.receive(), Receive)| logs the
call, performs the |receive|, and then logs the return.  Similarly, each
worker with an odd identity performs 20 |send| executions of random values.
This definition is designed so that an even number of workers with contiguous
identities will not deadlock. 

|SyncChanSpec| is the synchronisation specification object from earlier.  The
way executions synchronise is captured by the function |matching|.  This is a
partial function whose domain defines which operation executions can
synchronise together, and, in that case, the value each should return: here
|send(x)| and |receive| can synchronise, giving a result as defined but the
synchronisation specification object.  (Alternatively, the call to
|SyncChanSpec.sync| can be in-lined.)

The function |doTest| performs a single test.  This uses a
|BinaryStatelessTester| object from the testing framework, which encapsulates
the search from Section~\ref{sec:binary-heterogeneous}.  Here, the tester runs
8 |worker| threads, and tests the resulting history against |matching|.  If a
non-synchronisation-linearisable history is recorded, it displays this for the
user.  The |main| function runs |doTest| either 5000 times or until an error
is found.  The tester can be adapted to test for synchronisation
progressibility by passing a timeout duration to the |BinaryStatelessTester|.

Other classes of testers are similar.  In the case of a stateful
specification, the |matching| function takes the specification object as a
parameter, and also returns the new value of the specification object.

