\section{Direct testing of synchronisation linearisation and progressability}
\label{sec:direct}

We now consider how to test for synchronisation linearisation more directly.
We also consider how to test for synchronisation progressibility.  
We perform logging precisely as for standard linearisation: a thread that
performs a particular operation~$\sm{op}^i(x)$: (1) writes
$\call.\sm{op}^i(x)$ into the log; (2)~performs $\sm{op}(x)$ on the
synchonisation object, obtaining result~$y$, say; (3)~writes
$\return.\sm{op}^i \:: y$ into the log.  

When testing for synchronisation linearisation, we again make it the
responsibility of the tester to define the worker threads in a way that
ensures that all operation executions will be able to synchronise, so all
threads will eventually terminate. 
%%  For example, for a binary heterogeneous synchronisation object, threads
%% collectively should perform the same number of each operation.

When testing for progress, we remove the requirement on the tester to ensure
that all operation executions can synchronise.  Indeed, in some cases, in
order to find failures of progress, it is necessary that not all executions
can synchronise: we have examples of incorrect synchronisation objects where
(for example) if there are two executions of $\op_1$ and one of~$\op_2$, then
it's possible that \emph{neither} execution of~$\op_1$ returns, signifying
a failure of progressability; but if there were a second execution
of~$\op_2$, it would unblock both executions of~$\op_1$, so all executions
would return, and the failure of progressability would be missed.

Instead, we run threads performing operations, typically chosen at random; and
after a suitable duration, we interrupt any threads that have not yet
returned.  The duration before the interrupts needs to be chosen so that if
any threads have not returned by that point, then (almost certainly) they
really are stuck: otherwise this approach it likely to produce false
positives.  Our informal experiments suggest that a duration of 100ms is
appropriate (at least, on the architecture we were using): we have not
observed any false positives with this duration, but did with a shorter
duration of 80ms.  This delay does significantly increase the time that a
given number of runs will take.

In the remainder of this section we consider algorithms for determining
whether the resulting log history is synchronisation linearisable, and whether
it is synchronisation progressable.  These algorithms again assume that the
synchronisation specification object is deterministic.  In
Section~\ref{sec:algorithm-dfs} we present a general algorithm for this
problem, based on depth-first search.  We also show how the algorithm can be
extended to test for synchronisation progressibility.

We then consider the complexity of this problem.  We show, in
Section~\ref{sec:NP-complete}, that, for a \emph{stateful} synchronisation
object, the problem of deciding whether a history is synchronisation
linearisable is NP-complete in general.  However, we show that in the case of
\emph{binary} synchronisations with a \emph{stateless} specification object,
the problem can be solved in polynomial time: we consider the heterogeneous
case in Section~\ref{sec:binary-heterogeneous}, and the homogeneous case in
Section~\ref{sec:binary-homogeneous}.  Nevertheless, in
Section~\ref{sec:non-binary-stateless} we show that for synchronisations of
three or more executions, the problem is again NP-complete, even in the
stateless case.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The general case}
\label{sec:algorithm-dfs}

We describe an algorithm for deciding whether a given complete history~$h$ is
synchronisation linearisable with respect to a given synchronisation
specification object.  We transform the problem into a graph-search algorithm
as follows.

We define a search graph, where each node is a \emph{configuration}
comprising:
%
\begin{itemize}
\item An index $i$ into the log;

\item A set $pending$ of operation executions that were called in the
  first~$i$ events of the log and that have not yet been linearised;

\item A set $linearised$ of operation executions that were called in the
  first~$i$ events of the log and that have been linearised, but have not yet
  returned;

\item The state $spec$ of the specification object after the synchronisations
  linearised so far.
\end{itemize}
%
From such a configuration, there are edges to configurations as follows:
%
\def\edgeFont#1{\rm\textsf{#1}}
\begin{description}
\item[\edgeFont{Synchronisation}.] If some set of executions in $pending$ can
  synchronise, giving the same results as required by the
  specification~$spec$, then there is an edge to a configuration where the
  synchronising executions are moved into $linearised$, and $spec$ is updated
  corresponding to the synchronisation;

\item[\edgeFont{Call}.] If the next event in the log is a $\call$ event, then
  there is an edge where that event is added to $pending$, and $i$ is
  advanced;

\item[\edgeFont{Return}.] If the next event in the log is a $\return$ event,
  and the corresponding execution is in $linearised$, then there is an edge
  where that execution is removed from $linearised$, and $i$ is advanced.
\end{description}
%
The initial configuration has $i$ at the start of the log, $pending$ and
$linearised$ empty, and $spec$ the initial state of the specification object.
Target configurations have $i$ at the end of the log, and $pending$ and
$linearised$ empty.

Any path from the initial configuration to a target configuration clearly
represents an interleaving of a history of the specification object with~$h$,
as required for synchronisation linearisation.  We can therefore search this
graph using a standard algorithm.  Our implementation uses depth-first search.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsubsection{Progress}

It is straightforward to adapt the search algorithm to also test for progress.
We change the definition of a target configuration to have $i$ at the end of
the log, $linearised$ empty, and such that no set of executions in $pending$
can synchronise: this ensures that we are dealing with a \emph{maximal}
synchronisation linearisation.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Partial-order reduction}

We have investigated a form of partial-order reduction, which we call
\emph{ASAP linearisation}.  The idea is that we try to linearise executions
\emph{as soon as possible}.
%
\begin{definition}
Let $h$ be a complete history of a synchronisation object, and let~$h_s$ be a
legal history of the corresponding specification object; and consider an
interleaving, as required for synchronisation linearisation.  We say that the
interleaving is an \emph{ASAP interleaving} if every event in~$h_s$ appears
either: (1)~directly after the $\call$ event of one of the corresponding
executions from~$h$; or (2)~directly after another event from~$h_s$.
\end{definition}
%
The following lemma shows that it suffices to consider ASAP interleavings.
%
\begin{lemma}
Let $h$ be a complete history of a synchronisation object, and let~$h_s$ be a
legal history of the corresponding specification object.  If $h_s$ is a
synchronisation linearisation of~$h$, then there is an ASAP interleaving of
them.
\end{lemma}
%
\begin{proof}
Consider an interleaving of~$h$ and~$h_s$, as required for synchronisation
linearisation.  We transform it into an ASAP interleaving as follows.  Working
forwards through the interleaving, we move every event of $h_s$ earlier in the
interleaving, as far as possible, without it moving past any of the corresponding
$\call$ events, nor moving past any other event from~$h_s$.  This means that
subsequently each such event follows either a corresponding $\call$ event or
another event from~$h_s$.

Each event from~$h_s$ is still between the $\call$ and $\return$
events of the corresponding executions.  Further, we do not reorder events
from~$h_s$ so the resulting interleaving is still an interleaving of~$h$
and~$h_s$.

Thus the resulting interleaving is an ASAP interleaving.
\end{proof}
%
Our approach, then, is to trim the search graph by removing
\edgeFont{synchronisation} edges that do not correspond to an ASAP
linearisation: after a \edgeFont{call} edge, we attempt to linearise a
synchronisation corresponding to that call, and then, if successful, to
linearise an arbitrary sequence of other synchronisations; but we do not
otherwise allow synchronisations.

Our experience is that this tactic is moderately successful.  In some cases,
it can reduce the total time to check histories by over~30\%;
although in some cases the gains are smaller, sometimes negligible.  The gains
seem highest in examples where there can be a reasonably large number of
pending executions.
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Complexity}
\label{sec:NP-complete}

Consider the problem of testing whether a given concurrent history is
synchronisation linearisable with respect to a given synchronisation
specification object.  We show that this problem is NP-complete in general.

We make use of a result from~\cite{gibbons-korach} concerning the complexity
of the corresponding problem for linearisation.  Let |Variable| be a
linearisation specification object corresponding to an integer variable with
|get| and |set| operations.  Then the problem of deciding whether a given
concurrent history is linearisable with respect to |Variable| is NP-complete
in general.

Since standard linearisation is a special case of synchronisation
linearisation (in the trivial case of unary synchronisations), this
immediately implies that deciding synchronisation linearisation is
NP-complete.  However, even if we restrict to the non-trivial case of binary
synchronisations, the result still holds.
%
We consider concurrent synchronisation histories on an object with the
following signature, which mimics the behaviour of a variable but via
synchronisations. 
%
\begin{scala}
object VariableSync{
  def op£\s1£(op: String, x: Int): Int
  def op£\s2£(u: Unit): Unit
} 
\end{scala}
%
The intention is that |op|\s1|("get", x)| acts like |get(x)|, and
|op|\s1|("set", x)| acts like |set(x)| (but returns -1).  The |op|\s2
operation does nothing except synchronise with~|op|\s1.  This
can be captured formally by the following synchronisation specification
object.
%
\begin{scala}
object VariableSyncSpec{
  private var state = 0   // The value of the variable.
  def sync((op, x): (String, Int), u: Unit): (Int, Unit) = 
    if(op == "get") (state, ()) else{ state = x; (-1, ()) }
}
\end{scala}

Let |ConcVariable| be a concurrent object that represents an integer variable.
Given a history~$h$ of |ConcVariable|, we build a history~$h'$ of
|VariableSync| as follows.  We replace every call or return of |get(x)| by
(respectively) a call or return of |op|\s1|("get", x)|; and we do similarly
with |set|s.  If there are $k$ calls of |get| or |set| in total, we prepend
$k$ calls of |op|\s2, and append $k$ corresponding returns (in any order).
%
Then it is clear that $h$ is linearisable with respect to |Variable| if and
only if $h'$ is linearisable with respect to |VariableSyncSpec|.  Deciding the
former is NP-complete; hence the latter is also. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The binary heterogeneous stateless case}
\label{sec:binary-heterogeneous}

The result of the previous subsection used a \emph{stateful} specification
object.  We now consider the \emph{stateless} case.  We show that for binary
heterogeneous synchronisations, the problem of deciding whether a history is
synchronisation linearisable can be decided in quadratic time.  We consider
the homogeneous case in the next subsection.

So consider a binary heterogeneous synchronisation object, whose specification
object is stateless.  In this case we do not need to worry about the
order of synchronisations: if each individual synchronisation is correct, then
any permutation will also be correct from the point of view of the
specification object; and we can order the synchronisations in a way that is
compatible with the concurrent history.  Informally, the idea is to find
matching operation executions in the concurrent history that could correspond
to a particular synchronisation; we therefore reduce the problem to that of
finding a matching in a graph.

Define two complete operation executions to be \emph{compatible} if they could
be synchronised, i.e.~they overlap and the return values agree with those for
the specification object.  For $n$ executions of operations this can be
calculated in $O(n^2)$.

Consider the bipartite graph where the two sets of nodes are executions
of~$\op_1$ and~$\op_2$, respectively, and there is an edge between two
executions if they are compatible.  A synchronisation linearisation then
corresponds to a total matching of this graph: given a total matching, we
build a synchronisation linearisation by including events
$\sync^{i_1,i_2}(x_1,x_2)\::(y_1,y_2)$ (in an appropriate order) whenever
there is an edge between $\op_1^{i_1}(x_1)\::y_1$ and $\op_2^{i_2}(x_2)\::y_2$
in the matching; and conversely, each synchronisation linearisation
corresponds to a total matching.

Thus we have reduced the problem to that of deciding whether there is a total
matching, for which standard algorithms exist.  We use the Ford-Fulkerson
method~\cite{ford-fulkerson}, which runs in time $O(n^2)$.

It is straightforward to extend this to a mix of binary and unary
synchronisations, again with a stateless specification object: the executions
of unary operations can be considered in isolation.  

This approach can be easily extended to also test for progress.  It is enough
to additionally check that no two pending executions could synchronise.

%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The binary homogeneous stateless case}
\label{sec:binary-homogeneous} 

We now consider the case of binary \emph{homogeneous} synchronisations with a
stateless specification object.  This case is almost identical to the case
with heterogeneous synchronisations, except the graph produced is not
necessarily bipartite.  Thus we have reduced the problem to that of finding a
total matching in a general graph.  This problem can be solved using, for
example, the blossom algorithm~\cite{edmonds_1965}, which runs in time
$O(n^4)$.
  
% Can also be done in time $O(n^{2.5})$.
%\verb!https://en.wikipedia.org/wiki/Maximum_cardinality_matching!

%We haven't implemented this. 

In fact, our experiments use a simpler algorithm.  We attempt to find a
matching via a depth-first search: we pick a node~$n$ that has not yet been
matched, try matching it with some unmatched compatible node~$n'$, and recurse
on the remainder of the graph; if that recursive search is unsuccessful, we
backtrack and try matching~$n$ with a different node.  We guide this search by
the standard heuristic of, at each point, expanding the node~$n$ that has
fewest unmatched compatible nodes~$n'$.  

In our only example of this category, the |Exchanger| from the Introduction,
we can choose the values to be exchanged randomly from a reasonably large
range (say size~100).  Then we can nearly always find a node~$n$ for which
there is a unique unmatched compatible node: this means that the algorithm
nearly always runs in linear time.  We expect that similar techniques could be
used for other examples in this category.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The non-binary stateless case}
\label{sec:non-binary-stateless}

It turns out that for synchronisations of arity greater than~2, the problem of
deciding whether a history is synchronisation linearisable is NP-complete in
general, even in the stateless case.  We prove this fact by reduction from the
following problem, which is known to be NP-complete~\cite{Karp1972}.
%
\begin{definition}
The problem of finding a total matching in a 3-partite hypergraph is as
follows: given disjoint finite sets $X$, $Y$ and~$Z$ of the same cardinality,
and a set $T \subseteq X \times Y \times Z$, find $U \subseteq T$ such that
each member of~$X$, $Y$ and~$Z$ is included in precisely one element of~$U$.
\end{definition}

Suppose we are given an instance $(X, Y, Z, T)$ of the above problem.  We
construct a synchronisation specification and a corresponding history~$h$ such
that $h$ is synchronisation linearisable if and only if a total matching
exists.  The synchronisations are between operations as follows:
\begin{scala}
  def op£\s1£(x: X): Unit
  def op£\s2£(y: Y): Unit
  def op£\s3£(z: Z): Unit
\end{scala}
%
The synchronisations are specified by:
%
\begin{scala}
  def sync(x: X, y: Y, z: Z): (Unit, Unit, Unit) = {
    require(£$(\sm x, \sm y, \sm z) \in T$£); ((), (), ())
  }
\end{scala}
%
The history~$h$ starts with calls of |op|$_1(x)$ for each $x \in X$,
|op|$_2(y)$ for each $y \in Y$, and |op|$_3(z)$ for each $z \in Z$ (in any
order); and then continues with returns of the same executions (in any
order).  It is clear that any synchronisation linearisation corresponds to a
total matching, i.e.~the executions that synchronise correspond to the
total matching~$U$.  Hence finding a synchronisation linearisation is
NP-complete. 

Our implementation for these cases uses a depth-first search to find a
matching, very much like in the binary homogeneous case.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
