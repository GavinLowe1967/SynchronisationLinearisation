\section{Direct testing of synchronisation linearisation}
\label{sec:direct}

We now consider how to test for synchronisation linearisation more directly.
We perform logging precisely as for standard linearisation: a thread that
performs a particular operation~$\sm{op}^i(x)$: (1) writes
$\call.\sm{op}^i(x)$ into the log; (2)~performs $\sm{op}(x)$ on the
synchonisation object, obtaining result~$y$, say; (3)~writes
$\return.\sm{op}^i \:: y$ into the log.  

When not testing for progress, we make it the responsibility of the tester to
define the threads in a way that ensures that all invocations will be able to
synchronise, so all threads will eventually terminate.  For example, for a
binary heterogeneous synchronisation object, threads collectively should
perform the same number of each operation. 

When testing for progress, we remove the requirement on the tester to ensure
that all invocations can synchronise.  Indeed, in some cases, in order to find
failures of progress, it is necessary that not all invocations can
synchronise: we have examples of incorrect synchronisation objects where (for
example) if there are two invocations of $\op_1$ and one of~$\op_2$, then
\emph{neither} invocation of~$\op_1$ returns, signifying the failure of
progressability; but if there were a second invocation of~$\op_2$, it would
unblock both invocations of~$\op_1$, so all invocations would return, and the
failure of progressability would be missed.

Instead, we run threads performing operations, typically chosen at random; and
after a suitable duration, we interrupt any threads that have not yet
returned.  The duration before the interrupts needs to be chosen so that it is
highly likely that any threads that have not returned really are stuck:
otherwise this approach it likely to produce false positives.  In practice, we
have found it easy to identify a suitable duration.  A downside of this
approach is that the duration needs to be chosen fairly conservatively, which
increases the time that a given number of runs will take.

\framebox{Discuss progress later?}

In the remainder of this section we consider algorithms for determining if the
resulting log history is synchronisation linearisable, and whether it also
satisfies progressability.  In Section~\ref{sec:algorithm-dfs} we present a
general algorithm for this problem, based on depth-first search.  We then
consider the complexity of this problem.  We show, in
Section~\ref{sec:NP-complete}, that, in the case of a stateful synchronisation
object, the problem of deciding whether a history is synchronisation
linearisable is NP-complete in general.  However, we show that in the case of
binary synchronisations with a stateless specification object the problem can
be solved in polynomial time: we consider the heterogeneous case in
Section~\ref{sec:binary-heterogeneous}, and the homogeneous case in
Section~\ref{sec:binary-homogeneous}.  Nevertheless, in
Section~\ref{sec:non-binary-stateless} we show that for synchronisations of
three or more invocations, the problem is again NP-complete, even in the
stateless case.

%%  It turns out that the appropriate
%% algorithm, and corresponding complexity results, differ depending upon the
%% nature of the synchronisation object: whether synchronisations are binary, or
%% may involve more than two threads; and whether the object is stateful or
%% stateless. 

%% Main ideas: general algorithm; NP-complete in general case; quadratic in
%% stateless binary heterogeneous case; polynomial in binary homogeneous case;
%% NP-complete for synchronisations of arity more than~2 even in stateless case


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The general case}
\label{sec:algorithm-dfs}

We describe an algorithm for deciding whether a given complete history~$h$ is
synchronisation linearisable with respect to a given synchronisation
specification object.  We transform the problem into a graph-search algorithm
as follows.

We define a search graph, where each node is a \emph{configuration}
comprising:
%
\begin{itemize}
\item An index $i$ into the log;

\item A set $pending$ of operation invocations that were called in the
  first~$i$ events of the log and that have not yet been linearised;

\item A set $linearised$ of operation invocations that were called in the
  first~$i$ events of the log and that have been linearised, but have not yet
  returned;

\item The state $spec$ of the specification object after the synchronisations
  linearised so far.
\end{itemize}
%
From such a configuration, there are edges to configurations as follows:
%
\def\edgeFont#1{\textsf{#1}}
\begin{description}
\item[\edgeFont{Synchronisation}.] If some set of invocations in $pending$ can
  synchronise, giving results compatible with~$spec$, then there is an edge to
  a configuration where the synchronising invocations are moved into
  $linearised$, and the specification object is updated corresponding to the
  synchronisation;

\item[\edgeFont{Call}.] If the next event in the log is a $\call$ event, then
  there is an edge where that event is added to $pending$, and $i$ is
  advanced;

\item[\edgeFont{Return}.] If the next event in the log is a $\return$ event,
  and the corresponding invocation is in $linearised$, then that invocation is
  removed from $linearised$, and $i$ is advanced.
\end{description}
%
The initial configuration has $i$ at the start of the log, $pending$ and
$linearised$ empty, and $spec$ the initial state of the specification object.
Target configurations have $i$ at the end of the log, and $pending$ and
$linearised$ empty.

Any path from the initial configuration to a target configuration clearly
represents an interleaving of a history of the specification object with~$h$,
as required for compatibility.  We can therefore search this graph using a
standard algorithm.  Our implementation uses depth-first search.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Progress}

It is straightforward to adapt the search algorithm to also test for progress.
It is enough to change configurations as follows, following the definition of
progressability.
%
\begin{itemize}
\item The definition of \edgeFont{synchronisation} edges is changed so that they
  involve only invocations that do subsequently return.
  %% : this ensures that all invocations that synchronised did return.

\item The definition of target configurations is changed so that $pending$ may
  be non-empty, but must contain no set of invocations that can synchronise
  according to~$spec$ (i.e.~satisfying the precondition in~$spec$).  (However,
  $linearised$ must still be empty.)  This ensures that there no further
  synchronisations are possible at the end.
\end{itemize}

\framebox{??} Why not leave \edgeFont{synchronisation} edges unchanged, since
we require $linearised$ to be empty?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Partial-order reduction}

We have investigated a form of partial-order reduction, which we call
\emph{ASAP linearisation}.  The idea is that we try to linearise invocations
as soon as possible.
%
\begin{definition}
Let $h$ be a complete history of a synchronisation object, and let~$h_s$ be a
legal history of the corresponding specification object; and consider an
interleaving, as required for synchronisation compatibility.  We say that the
interleaving is an \emph{ASAP interleaving} if every event in~$h_s$ appears
either: (1)~directly after the $\call$ event of one of the corresponding
invocations from~$h$; or (2)~directly after another event from~$h_s$.
\end{definition}
%
\begin{lemma}
Let $h$ be a complete history of a synchronisation object, and let~$h_s$ be a
legal history of the corresponding specification object.  If $h$ and~$h_s$ are
synchronisation-compatible, then there is an ASAP interleaving of them.
\end{lemma}
%
\begin{proof}
Consider an interleaving of~$h$ and~$h_s$, as required for synchronisation
compatibility.  We transform it into an ASAP interleaving as follows.  Working
forwards through the interleaving, we move every event of $h_s$ earlier in the
interleaving, as far as possible, without it moving past any of the corresponding
$\call$ events, nor moving past any other event from~$h_s$.  This means that
subsequently each such event follows either a corresponding $\call$ event or
another event from~$h_s$.

Note that each event from~$h_s$ is still between the $\call$ and $return$
events of the corresponding invocations.  Further, we do not reorder events
from~$h_s$ so the resulting interleaving is still an interleaving of~$h$
and~$h_s$.

Thus the resulting interleaving is an ASAP interleaving.
\end{proof}
%
Our approach, then is to trim the search graph by removing
\edgeFont{synchronisation} edges that do not correspond to an ASAP
linearisation: after a \edgeFont{call} edge, we attempt to linearise a
synchronisation corresponding to that call, and then, if successful, to
linearise an arbitrary sequence of other synchronisations; but we do not
otherwise allow linearisations.

Our experience is that this tactic is moderately successful.  In some cases,
it can reduce the total time to check a fixed number of runs by over~30\%;
although in most cases the gains are smaller, sometimes negligible.  The gains
seem highest in examples where there can be a reasonably large number of
pending invocations.
 
%% \framebox{**} Our implementation employs a partial-order reduction.  This
%% allows synchronisation edges only after a call edge or another synchronisation
%% edge, with the first synchronisation in each such sequence including the
%% invocation corresponding to the call.  \framebox{**} Test whether this
%% actually helps.  If so, justify better.



%% Partial order reduction: a synchronisation point must follow either the
%% call of one of the concurrent operations, or another synchronisation
%% point.  Any synchronisation history can be transformed into this form, by
%% moving synchronisation points earlier, but not before any of the corresponding
%% call events, and preserving the order of synchronisations.  This means that
%% after advancing past the call of an invocation, we may synchronise that
%% invocation, and then an arbitrary sequence of other invocations. 

%% Alternatively, a synchronisation point must precede either the return of one
%% of the concurrent operations, or another synchronisation point.  This is more
%% like the JIT technique in the linearisability testing paper.  This means that
%% before advancing in the log to the return of an invocation that has not
%% synchronised, we synchronise some invocations, ending with the one in
%% question.  And we only synchronise in these circumstances. 

%% My intuition is that the former is more efficient: in the latter, we might
%% investigate synchronising other invocations even though the returning
%% operation can't be synchronised with any invocation.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Complexity}
\label{sec:NP-complete}

Consider the problem of testing whether a given concurrent history is
synchronisation linearisable with respect to a given synchronisation
specification object.  We show that this problem is NP-complete in general.


We make use of a result from~\cite{gibbons-korach} concerning the complexity
of the corresponding problem for linearisability.  Let |Variable| be a
linearisability specification object corresponding to a variable with |get|
and |set| operations.  Then the problem of deciding whether a given concurrent
history is linearisable with respect to |Variable| is NP-complete.

Since standard linearisation is a special case of synchronisation
linearisation (in the trivial case of no synchronisations), this immediately
implies that deciding synchronisation linearisation is NP-complete.  However,
even if we restrict to the non-trivial case of binary synchronisations, the
result still holds.

We consider concurrent synchronisation histories on an object with the
following signature, which mimics the behaviour of a variable but via
synchronisations. 
%
\begin{scala}
object VariableSync{
  def op£\s1£(op: String, x: Int): Int
  def op£\s2£(u: Unit): Unit
} 
\end{scala}
%
The intention is that |op|\s1|("get", x)| acts like |get(x)|, and
|op|\s1|("set", x)| acts like |set(x)| (but returns -1).  The |op|\s2
invocations do nothing except synchronise with invocations of~|op|\s1.  This
can be captured formally by the following synchronisation specification
object.
%
\begin{scala}
object VariableSyncSpec{
  private var state = 0
  def sync((op, x): (String, Int), u: Unit): (Int, Unit) = 
    if(op == "get") (state, ()) else{ state = x; (-1, ()) }
}
\end{scala}


Let |ConcVariable| be a concurrent object that represents a variable.  Given a
history~$h$ of |ConcVariable|, we build a history~$h'$
of |VariableSync| as follows.  We replace every call or return of |get(x)| by
(respectively) a call or return of |op|\s1|("get", x)|; and we do similarly
with |set|s.  If there are $k$ calls of |get| or |set| in total, we prepend
$k$ calls of |op|\s2, and append $k$ corresponding returns (in any order).
%
Then it is clear that $h$ is linearisable with respect to |Variable| if and
only if $h'$ is linearisable with respect to |VariableSyncSpec|.  Deciding the
former is NP-complete; hence the latter is also. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The binary heterogeneous stateless case}
\label{sec:binary-heterogeneous}

The result of the previous subsection used a stateful specification object.
We now consider the stateless case for binary heterogeneous synchronisations.
We show that in this case the problem of deciding whether a history is
synchronisation linearisable can be decided in quadratic time.

So consider a binary synchronisation object, whose specification object is
stateless.  Note that in this case we do not need to worry about the order of
synchronisations: if each individual synchronisation is correct, then any
permutation of them will be synchronisation-linearisable.

Define two complete invocations to be \emph{compatible} if they could be
synchronised, i.e.~they overlap and the return values agree with those for the
specification object.  For $n$ invocations of operations this can be
calculated in $O(n^2)$.

Consider the bipartite graph where the two sets of nodes are invocations
of~$\op_1$ and~$\op_2$, respectively, and there is an edge between two
invocations if they are compatible.  A synchronisation linearisation then
corresponds to a total matching of this graph: given a total matching, we
build a synchronisation-compatible history of the synchronisation
specification object by including events
$\sync^{i_1,i_2}(x_1,x_2)\::(y_1,y_2)$ (in an arbitrary order) whenever there
is an edge between $\op_1^{i_1}(x_1)\::y_1$ and $\op_2^{i_2}(x_2)\::y_2$ in
the matching; and conversely, each synchronisation-compatible history
corresponds to a total matching.

Thus we have reduced the problem to that of deciding whether a total matching
exits, for which standard algorithms exist.  We use the Ford-Fulkerson method,
which runs in time $O(n^2)$.

It is straightforward to extend this to a mix of binary and unary
synchronisations, again with a stateless specification object: the invocations
of unary operations can be considered in isolation.  

This approach can be easily extended to also test for progress.  It is enough
to additionally check that no two pending invocations could synchronise.

%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The binary homogeneous stateless case}
\label{sec:binary-homogeneous} 

We now consider the case of binary homogeneous synchronisations with a
stateless specification object.  This case is almost identical to the case
with heterogeneous synchronisations, except the graph produced is not
necessarily bipartite.  Thus we have reduced the problem to that of finding a
maximum matching in a general graph, which can be solved using, for example,
the blossom algorithm~\cite{edmonds_1965}, which runs in time $O(n^4)$.
  
% Can also be done in time $O(n^{2.5})$.
%\verb!https://en.wikipedia.org/wiki/Maximum_cardinality_matching!

%We haven't implemented this. 

In fact, our experiments use a simpler algorithm.  We attempt to find a
matching via a depth-first search: we pick a node~$n$ that has not yet been
matched, try matching it with some unmatched compatible node~$n'$, and recurse
on the remainder of the graph; if that recursive search is unsuccessful, we
backtrack and try matching~$n$ with a different node.  We guide this search by
the standard heuristic of, at each point, expanding the node~$n$ that has
fewest unmatched compatible nodes~$n'$.  

In our only example of this category, the |Exchanger| from the Introduction,
we can choose the values to be exchanged randomly from a reasonably large
range (say size~100).  Then we can nearly always find a node~$n$ for which
there is a unique unmatched compatible node: this means that the algorithm
nearly always runs in linear time.  We expect that similar techniques could be
used in other examples in this category.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The non-binary  stateless case}
\label{sec:non-binary-stateless}

It turns out that for synchronisations of arity greater than~2, the problem of
deciding whether a history is synchronisation linearisable is NP-complete in
general, even in the stateless case.  We prove this fact by reduction from the
following problem, which is known to be NP-complete~\cite{Karp1972}.
%
\begin{definition}
The problem of finding a complete matching in a 3-partite hypergraph is as
follows: given disjoint finite sets $X$, $Y$ and~$Z$ of the same cardinality,
and a set $T \subseteq X \times Y \times Z$, find $U \subseteq T$ such that
each member of~$X$, $Y$ and~$Z$ is included in precisely one element of~$T$.
\end{definition}

Suppose we are given an instance $(X, Y, Z, T)$ of the above problem.  We
construct a synchronisation specification and a corresponding history~$h$ such
that $h$ is synchronisation linearisable if and only if a complete matching
exists.  The synchronisations are between operations as follows:
\begin{scala}
  def op£\s1£(x: X): Unit
  def op£\s2£(y: Y): Unit
  def op£\s3£(z: Z): Unit
\end{scala}
%
The synchronisations are specified by:
%
\begin{scala}
  def sync(x: X, y: Y, z: Z): (Unit, Unit, Unit) = {
    require(£$(\sm x, \sm y, \sm z) \in T$£); ((), (), ())
  }
\end{scala}
%
The history~$h$ starts with calls of |op|$_1(x)$ for each $x \in X$,
|op|$_2(y)$ for each $y \in Y$, and |op|$_3(z)$ for each $z \in Z$ (in any
order); and then continues with returns of the same invocations (in any
order).  It is clear that any synchronisation linearisation corresponds to a
complete matching, i.e.~the invocations that synchronise correspond to the
complete matching~$U$.

Our implementation uses a depth-first search to find a matching, very much
like in the binary homogeneous case. 
